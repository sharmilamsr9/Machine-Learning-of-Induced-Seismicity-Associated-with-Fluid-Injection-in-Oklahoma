{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('my_df_train.pickle')\n",
    "df_test = pd.read_pickle('my_df_test.pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2513, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2513, 26) (2513,)\n",
      "(729, 26) (729,)\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "inj_vol = np.stack(df_train['inj_vol'].values)\n",
    "# ignore neighbors and take data for the current co-ordinate\n",
    "inj_vol = inj_vol[:,:,0]\n",
    "pp = np.stack(df_train['pp'].values)\n",
    "# ignore neighbors and take data for the current co-ordinate\n",
    "pp = pp[:,:,0]\n",
    "lat = np.stack(df_train['lat'].values)\n",
    "lat = np.reshape(lat,(-1,1))\n",
    "lon = np.stack(df_train['lon'].values)\n",
    "lon = np.reshape(lon,(-1,1))\n",
    "\n",
    "\n",
    "\n",
    "# dim: 2814 x 24\n",
    "x_train = np.concatenate([lat, lon, inj_vol, pp], axis =1)\n",
    "y_train = df_train['lambda'].values\n",
    "\n",
    "# test\n",
    "inj_vol = np.stack(df_test['inj_vol'].values)\n",
    "# ignore neighbors and take data for the current co-ordinate\n",
    "inj_vol = inj_vol[:,:,0]\n",
    "pp = np.stack(df_test['pp'].values)\n",
    "# ignore neighbors and take data for the current co-ordinate\n",
    "pp = pp[:,:,0]\n",
    "lat = np.stack(df_test['lat'].values)\n",
    "lat = np.reshape(lat,(-1,1))\n",
    "lon = np.stack(df_test['lon'].values)\n",
    "lon = np.reshape(lon,(-1,1))\n",
    "\n",
    "\n",
    "# dim: _ x 24\n",
    "x_test = np.concatenate([lat, lon, inj_vol, pp], axis =1)\n",
    "y_test = df_test['lambda'].values\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "class Feedforward(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Feedforward, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size  = hidden_size\n",
    "        # create layers\n",
    "        self.fc1 = nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(self.hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        hidden = self.fc1(x)\n",
    "        relu = self.relu(hidden)\n",
    "        output = self.fc2(relu)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert train test data to torch tensors\n",
    "X_train = torch.from_numpy(x_train.astype('float32'))\n",
    "Y_train = torch.from_numpy(np.expand_dims(y_train, axis=-1).astype('float32'))\n",
    "X_test = torch.from_numpy(x_test.astype('float32'))\n",
    "Y_test = torch.from_numpy(np.expand_dims(y_test, axis=-1).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2513, 26]) torch.Size([2513, 1]) torch.float32 torch.float32\n",
      "torch.Size([729, 26]) torch.Size([729, 1]) torch.float32 torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape, X_train.dtype, Y_train.dtype)\n",
    "print(X_test.shape, Y_test.shape, X_test.dtype, Y_test.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed for initializing model weights\n",
    "torch.manual_seed(12345)\n",
    "model = Feedforward(x_train.shape[1], 32)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr = 0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 4.6124, test loss 14.5746\n",
      "Epoch 1: train loss: 44.8418, test loss 73.5516\n",
      "Epoch 2: train loss: 5.5058, test loss 20.8734\n",
      "Epoch 3: train loss: 4.9644, test loss 14.5657\n",
      "Epoch 4: train loss: 15.7501, test loss 25.4147\n",
      "Epoch 5: train loss: 13.7892, test loss 22.8569\n",
      "Epoch 6: train loss: 6.1568, test loss 13.8823\n",
      "Epoch 7: train loss: 1.1472, test loss 8.0296\n",
      "Epoch 8: train loss: 1.0684, test loss 7.8472\n",
      "Epoch 9: train loss: 3.7159, test loss 10.9302\n",
      "Epoch 10: train loss: 5.7694, test loss 13.2293\n",
      "Epoch 11: train loss: 5.6091, test loss 12.7963\n",
      "Epoch 12: train loss: 3.7658, test loss 10.2622\n",
      "Epoch 13: train loss: 1.7030, test loss 7.3752\n",
      "Epoch 14: train loss: 0.5699, test loss 5.4901\n",
      "Epoch 15: train loss: 0.6477, test loss 5.0457\n",
      "Epoch 16: train loss: 1.4650, test loss 5.5424\n",
      "Epoch 17: train loss: 2.2848, test loss 6.1647\n",
      "Epoch 18: train loss: 2.5869, test loss 6.3297\n",
      "Epoch 19: train loss: 2.2720, test loss 5.9086\n",
      "Epoch 20: train loss: 1.5812, test loss 5.1506\n",
      "Epoch 21: train loss: 0.8868, test loss 4.4515\n",
      "Epoch 22: train loss: 0.4863, test loss 4.1123\n",
      "Epoch 23: train loss: 0.4792, test loss 4.2085\n",
      "Epoch 24: train loss: 0.7547, test loss 4.5801\n",
      "Epoch 25: train loss: 1.0840, test loss 4.9468\n",
      "Epoch 26: train loss: 1.2590, test loss 5.0659\n",
      "Epoch 27: train loss: 1.1938, test loss 4.8492\n",
      "Epoch 28: train loss: 0.9422, test loss 4.3748\n",
      "Epoch 29: train loss: 0.6422, test loss 3.8231\n",
      "Epoch 30: train loss: 0.4280, test loss 3.3718\n",
      "Epoch 31: train loss: 0.3651, test loss 3.1166\n",
      "Epoch 32: train loss: 0.4346, test loss 3.0451\n",
      "Epoch 33: train loss: 0.5635, test loss 3.0741\n",
      "Epoch 34: train loss: 0.6672, test loss 3.1063\n",
      "Epoch 35: train loss: 0.6914, test loss 3.0738\n",
      "Epoch 36: train loss: 0.6299, test loss 2.9632\n",
      "Epoch 37: train loss: 0.5181, test loss 2.8089\n",
      "Epoch 38: train loss: 0.4087, test loss 2.6667\n",
      "Epoch 39: train loss: 0.3446, test loss 2.5815\n",
      "Epoch 40: train loss: 0.3404, test loss 2.5658\n",
      "Epoch 41: train loss: 0.3804, test loss 2.5975\n",
      "Epoch 42: train loss: 0.4305, test loss 2.6353\n",
      "Epoch 43: train loss: 0.4578, test loss 2.6403\n",
      "Epoch 44: train loss: 0.4469, test loss 2.5946\n",
      "Epoch 45: train loss: 0.4042, test loss 2.5069\n",
      "Epoch 46: train loss: 0.3513, test loss 2.4041\n",
      "Epoch 47: train loss: 0.3115, test loss 2.3153\n",
      "Epoch 48: train loss: 0.2979, test loss 2.2580\n",
      "Epoch 49: train loss: 0.3085, test loss 2.2319\n",
      "Epoch 50: train loss: 0.3299, test loss 2.2228\n",
      "Epoch 51: train loss: 0.3459, test loss 2.2124\n",
      "Epoch 52: train loss: 0.3461, test loss 2.1885\n",
      "Epoch 53: train loss: 0.3301, test loss 2.1498\n",
      "Epoch 54: train loss: 0.3062, test loss 2.1048\n",
      "Epoch 55: train loss: 0.2853, test loss 2.0651\n",
      "Epoch 56: train loss: 0.2752, test loss 2.0383\n",
      "Epoch 57: train loss: 0.2772, test loss 2.0241\n",
      "Epoch 58: train loss: 0.2856, test loss 2.0151\n",
      "Epoch 59: train loss: 0.2925, test loss 2.0021\n",
      "Epoch 60: train loss: 0.2921, test loss 1.9784\n",
      "Epoch 61: train loss: 0.2840, test loss 1.9439\n",
      "Epoch 62: train loss: 0.2720, test loss 1.9043\n",
      "Epoch 63: train loss: 0.2619, test loss 1.8667\n",
      "Epoch 64: train loss: 0.2573, test loss 1.8365\n",
      "Epoch 65: train loss: 0.2582, test loss 1.8141\n",
      "Epoch 66: train loss: 0.2618, test loss 1.7966\n",
      "Epoch 67: train loss: 0.2639, test loss 1.7795\n",
      "Epoch 68: train loss: 0.2624, test loss 1.7598\n",
      "Epoch 69: train loss: 0.2574, test loss 1.7375\n",
      "Epoch 70: train loss: 0.2512, test loss 1.7146\n",
      "Epoch 71: train loss: 0.2465, test loss 1.6938\n",
      "Epoch 72: train loss: 0.2446, test loss 1.6765\n",
      "Epoch 73: train loss: 0.2450, test loss 1.6617\n",
      "Epoch 74: train loss: 0.2459, test loss 1.6474\n",
      "Epoch 75: train loss: 0.2457, test loss 1.6315\n",
      "Epoch 76: train loss: 0.2435, test loss 1.6132\n",
      "Epoch 77: train loss: 0.2401, test loss 1.5935\n",
      "Epoch 78: train loss: 0.2369, test loss 1.5741\n",
      "Epoch 79: train loss: 0.2348, test loss 1.5563\n",
      "Epoch 80: train loss: 0.2340, test loss 1.5405\n",
      "Epoch 81: train loss: 0.2340, test loss 1.5257\n",
      "Epoch 82: train loss: 0.2337, test loss 1.5106\n",
      "Epoch 83: train loss: 0.2325, test loss 1.4946\n",
      "Epoch 84: train loss: 0.2304, test loss 1.4775\n",
      "Epoch 85: train loss: 0.2282, test loss 1.4602\n",
      "Epoch 86: train loss: 0.2265, test loss 1.4433\n",
      "Epoch 87: train loss: 0.2254, test loss 1.4273\n",
      "Epoch 88: train loss: 0.2249, test loss 1.4121\n",
      "Epoch 89: train loss: 0.2243, test loss 1.3973\n",
      "Epoch 90: train loss: 0.2234, test loss 1.3827\n",
      "Epoch 91: train loss: 0.2220, test loss 1.3683\n",
      "Epoch 92: train loss: 0.2205, test loss 1.3544\n",
      "Epoch 93: train loss: 0.2192, test loss 1.3413\n",
      "Epoch 94: train loss: 0.2182, test loss 1.3289\n",
      "Epoch 95: train loss: 0.2175, test loss 1.3171\n",
      "Epoch 96: train loss: 0.2168, test loss 1.3053\n",
      "Epoch 97: train loss: 0.2159, test loss 1.2932\n",
      "Epoch 98: train loss: 0.2149, test loss 1.2807\n",
      "Epoch 99: train loss: 0.2137, test loss 1.2680\n",
      "Epoch 100: train loss: 0.2127, test loss 1.2554\n",
      "Epoch 101: train loss: 0.2118, test loss 1.2430\n",
      "Epoch 102: train loss: 0.2111, test loss 1.2311\n",
      "Epoch 103: train loss: 0.2104, test loss 1.2196\n",
      "Epoch 104: train loss: 0.2096, test loss 1.2085\n",
      "Epoch 105: train loss: 0.2087, test loss 1.1978\n",
      "Epoch 106: train loss: 0.2078, test loss 1.1875\n",
      "Epoch 107: train loss: 0.2070, test loss 1.1776\n",
      "Epoch 108: train loss: 0.2062, test loss 1.1679\n",
      "Epoch 109: train loss: 0.2056, test loss 1.1584\n",
      "Epoch 110: train loss: 0.2049, test loss 1.1486\n",
      "Epoch 111: train loss: 0.2042, test loss 1.1387\n",
      "Epoch 112: train loss: 0.2035, test loss 1.1284\n",
      "Epoch 113: train loss: 0.2027, test loss 1.1180\n",
      "Epoch 114: train loss: 0.2020, test loss 1.1076\n",
      "Epoch 115: train loss: 0.2014, test loss 1.0974\n",
      "Epoch 116: train loss: 0.2008, test loss 1.0875\n",
      "Epoch 117: train loss: 0.2002, test loss 1.0779\n",
      "Epoch 118: train loss: 0.1995, test loss 1.0687\n",
      "Epoch 119: train loss: 0.1989, test loss 1.0599\n",
      "Epoch 120: train loss: 0.1983, test loss 1.0514\n",
      "Epoch 121: train loss: 0.1977, test loss 1.0431\n",
      "Epoch 122: train loss: 0.1971, test loss 1.0349\n",
      "Epoch 123: train loss: 0.1965, test loss 1.0268\n",
      "Epoch 124: train loss: 0.1960, test loss 1.0186\n",
      "Epoch 125: train loss: 0.1954, test loss 1.0102\n",
      "Epoch 126: train loss: 0.1949, test loss 1.0018\n",
      "Epoch 127: train loss: 0.1943, test loss 0.9934\n",
      "Epoch 128: train loss: 0.1938, test loss 0.9850\n",
      "Epoch 129: train loss: 0.1933, test loss 0.9768\n",
      "Epoch 130: train loss: 0.1928, test loss 0.9689\n",
      "Epoch 131: train loss: 0.1923, test loss 0.9612\n",
      "Epoch 132: train loss: 0.1917, test loss 0.9537\n",
      "Epoch 133: train loss: 0.1912, test loss 0.9465\n",
      "Epoch 134: train loss: 0.1908, test loss 0.9394\n",
      "Epoch 135: train loss: 0.1903, test loss 0.9325\n",
      "Epoch 136: train loss: 0.1898, test loss 0.9256\n",
      "Epoch 137: train loss: 0.1893, test loss 0.9186\n",
      "Epoch 138: train loss: 0.1889, test loss 0.9117\n",
      "Epoch 139: train loss: 0.1884, test loss 0.9046\n",
      "Epoch 140: train loss: 0.1880, test loss 0.8976\n",
      "Epoch 141: train loss: 0.1875, test loss 0.8907\n",
      "Epoch 142: train loss: 0.1871, test loss 0.8839\n",
      "Epoch 143: train loss: 0.1867, test loss 0.8773\n",
      "Epoch 144: train loss: 0.1862, test loss 0.8708\n",
      "Epoch 145: train loss: 0.1858, test loss 0.8646\n",
      "Epoch 146: train loss: 0.1854, test loss 0.8585\n",
      "Epoch 147: train loss: 0.1850, test loss 0.8525\n",
      "Epoch 148: train loss: 0.1846, test loss 0.8466\n",
      "Epoch 149: train loss: 0.1842, test loss 0.8408\n",
      "Epoch 150: train loss: 0.1838, test loss 0.8350\n",
      "Epoch 151: train loss: 0.1834, test loss 0.8292\n",
      "Epoch 152: train loss: 0.1830, test loss 0.8234\n",
      "Epoch 153: train loss: 0.1827, test loss 0.8176\n",
      "Epoch 154: train loss: 0.1823, test loss 0.8119\n",
      "Epoch 155: train loss: 0.1819, test loss 0.8063\n",
      "Epoch 156: train loss: 0.1816, test loss 0.8008\n",
      "Epoch 157: train loss: 0.1812, test loss 0.7954\n",
      "Epoch 158: train loss: 0.1809, test loss 0.7902\n",
      "Epoch 159: train loss: 0.1805, test loss 0.7851\n",
      "Epoch 160: train loss: 0.1802, test loss 0.7801\n",
      "Epoch 161: train loss: 0.1798, test loss 0.7751\n",
      "Epoch 162: train loss: 0.1795, test loss 0.7702\n",
      "Epoch 163: train loss: 0.1792, test loss 0.7652\n",
      "Epoch 164: train loss: 0.1789, test loss 0.7603\n",
      "Epoch 165: train loss: 0.1785, test loss 0.7554\n",
      "Epoch 166: train loss: 0.1782, test loss 0.7505\n",
      "Epoch 167: train loss: 0.1779, test loss 0.7457\n",
      "Epoch 168: train loss: 0.1776, test loss 0.7410\n",
      "Epoch 169: train loss: 0.1773, test loss 0.7363\n",
      "Epoch 170: train loss: 0.1770, test loss 0.7317\n",
      "Epoch 171: train loss: 0.1767, test loss 0.7272\n",
      "Epoch 172: train loss: 0.1764, test loss 0.7228\n",
      "Epoch 173: train loss: 0.1761, test loss 0.7184\n",
      "Epoch 174: train loss: 0.1758, test loss 0.7141\n",
      "Epoch 175: train loss: 0.1755, test loss 0.7098\n",
      "Epoch 176: train loss: 0.1752, test loss 0.7055\n",
      "Epoch 177: train loss: 0.1750, test loss 0.7013\n",
      "Epoch 178: train loss: 0.1747, test loss 0.6970\n",
      "Epoch 179: train loss: 0.1744, test loss 0.6928\n",
      "Epoch 180: train loss: 0.1741, test loss 0.6887\n",
      "Epoch 181: train loss: 0.1739, test loss 0.6846\n",
      "Epoch 182: train loss: 0.1736, test loss 0.6805\n",
      "Epoch 183: train loss: 0.1733, test loss 0.6765\n",
      "Epoch 184: train loss: 0.1731, test loss 0.6726\n",
      "Epoch 185: train loss: 0.1728, test loss 0.6687\n",
      "Epoch 186: train loss: 0.1726, test loss 0.6648\n",
      "Epoch 187: train loss: 0.1723, test loss 0.6610\n",
      "Epoch 188: train loss: 0.1721, test loss 0.6572\n",
      "Epoch 189: train loss: 0.1718, test loss 0.6534\n",
      "Epoch 190: train loss: 0.1716, test loss 0.6497\n",
      "Epoch 191: train loss: 0.1714, test loss 0.6460\n",
      "Epoch 192: train loss: 0.1711, test loss 0.6423\n",
      "Epoch 193: train loss: 0.1709, test loss 0.6387\n",
      "Epoch 194: train loss: 0.1707, test loss 0.6351\n",
      "Epoch 195: train loss: 0.1705, test loss 0.6315\n",
      "Epoch 196: train loss: 0.1702, test loss 0.6280\n",
      "Epoch 197: train loss: 0.1700, test loss 0.6245\n",
      "Epoch 198: train loss: 0.1698, test loss 0.6211\n",
      "Epoch 199: train loss: 0.1696, test loss 0.6177\n",
      "Epoch 200: train loss: 0.1694, test loss 0.6143\n",
      "Epoch 201: train loss: 0.1692, test loss 0.6110\n",
      "Epoch 202: train loss: 0.1689, test loss 0.6077\n",
      "Epoch 203: train loss: 0.1687, test loss 0.6044\n",
      "Epoch 204: train loss: 0.1685, test loss 0.6011\n",
      "Epoch 205: train loss: 0.1683, test loss 0.5979\n",
      "Epoch 206: train loss: 0.1681, test loss 0.5947\n",
      "Epoch 207: train loss: 0.1679, test loss 0.5916\n",
      "Epoch 208: train loss: 0.1677, test loss 0.5885\n",
      "Epoch 209: train loss: 0.1675, test loss 0.5854\n",
      "Epoch 210: train loss: 0.1674, test loss 0.5823\n",
      "Epoch 211: train loss: 0.1672, test loss 0.5793\n",
      "Epoch 212: train loss: 0.1670, test loss 0.5763\n",
      "Epoch 213: train loss: 0.1668, test loss 0.5734\n",
      "Epoch 214: train loss: 0.1666, test loss 0.5704\n",
      "Epoch 215: train loss: 0.1664, test loss 0.5675\n",
      "Epoch 216: train loss: 0.1662, test loss 0.5647\n",
      "Epoch 217: train loss: 0.1661, test loss 0.5618\n",
      "Epoch 218: train loss: 0.1659, test loss 0.5590\n",
      "Epoch 219: train loss: 0.1657, test loss 0.5562\n",
      "Epoch 220: train loss: 0.1655, test loss 0.5534\n",
      "Epoch 221: train loss: 0.1654, test loss 0.5506\n",
      "Epoch 222: train loss: 0.1652, test loss 0.5478\n",
      "Epoch 223: train loss: 0.1650, test loss 0.5451\n",
      "Epoch 224: train loss: 0.1649, test loss 0.5424\n",
      "Epoch 225: train loss: 0.1647, test loss 0.5398\n",
      "Epoch 226: train loss: 0.1646, test loss 0.5372\n",
      "Epoch 227: train loss: 0.1644, test loss 0.5346\n",
      "Epoch 228: train loss: 0.1642, test loss 0.5320\n",
      "Epoch 229: train loss: 0.1641, test loss 0.5295\n",
      "Epoch 230: train loss: 0.1639, test loss 0.5269\n",
      "Epoch 231: train loss: 0.1638, test loss 0.5244\n",
      "Epoch 232: train loss: 0.1636, test loss 0.5219\n",
      "Epoch 233: train loss: 0.1635, test loss 0.5195\n",
      "Epoch 234: train loss: 0.1633, test loss 0.5170\n",
      "Epoch 235: train loss: 0.1632, test loss 0.5146\n",
      "Epoch 236: train loss: 0.1630, test loss 0.5123\n",
      "Epoch 237: train loss: 0.1629, test loss 0.5099\n",
      "Epoch 238: train loss: 0.1627, test loss 0.5076\n",
      "Epoch 239: train loss: 0.1626, test loss 0.5053\n",
      "Epoch 240: train loss: 0.1625, test loss 0.5029\n",
      "Epoch 241: train loss: 0.1623, test loss 0.5006\n",
      "Epoch 242: train loss: 0.1622, test loss 0.4984\n",
      "Epoch 243: train loss: 0.1620, test loss 0.4961\n",
      "Epoch 244: train loss: 0.1619, test loss 0.4939\n",
      "Epoch 245: train loss: 0.1618, test loss 0.4917\n",
      "Epoch 246: train loss: 0.1616, test loss 0.4895\n",
      "Epoch 247: train loss: 0.1615, test loss 0.4874\n",
      "Epoch 248: train loss: 0.1613, test loss 0.4852\n",
      "Epoch 249: train loss: 0.1612, test loss 0.4831\n",
      "Epoch 250: train loss: 0.1611, test loss 0.4810\n",
      "Epoch 251: train loss: 0.1609, test loss 0.4789\n",
      "Epoch 252: train loss: 0.1608, test loss 0.4768\n",
      "Epoch 253: train loss: 0.1607, test loss 0.4748\n",
      "Epoch 254: train loss: 0.1605, test loss 0.4727\n",
      "Epoch 255: train loss: 0.1604, test loss 0.4707\n",
      "Epoch 256: train loss: 0.1603, test loss 0.4687\n",
      "Epoch 257: train loss: 0.1601, test loss 0.4667\n",
      "Epoch 258: train loss: 0.1600, test loss 0.4647\n",
      "Epoch 259: train loss: 0.1599, test loss 0.4628\n",
      "Epoch 260: train loss: 0.1598, test loss 0.4609\n",
      "Epoch 261: train loss: 0.1596, test loss 0.4589\n",
      "Epoch 262: train loss: 0.1595, test loss 0.4570\n",
      "Epoch 263: train loss: 0.1594, test loss 0.4551\n",
      "Epoch 264: train loss: 0.1593, test loss 0.4532\n",
      "Epoch 265: train loss: 0.1592, test loss 0.4513\n",
      "Epoch 266: train loss: 0.1590, test loss 0.4494\n",
      "Epoch 267: train loss: 0.1589, test loss 0.4476\n",
      "Epoch 268: train loss: 0.1588, test loss 0.4457\n",
      "Epoch 269: train loss: 0.1587, test loss 0.4439\n",
      "Epoch 270: train loss: 0.1586, test loss 0.4421\n",
      "Epoch 271: train loss: 0.1585, test loss 0.4403\n",
      "Epoch 272: train loss: 0.1583, test loss 0.4385\n",
      "Epoch 273: train loss: 0.1582, test loss 0.4367\n",
      "Epoch 274: train loss: 0.1581, test loss 0.4350\n",
      "Epoch 275: train loss: 0.1580, test loss 0.4332\n",
      "Epoch 276: train loss: 0.1579, test loss 0.4315\n",
      "Epoch 277: train loss: 0.1578, test loss 0.4297\n",
      "Epoch 278: train loss: 0.1577, test loss 0.4280\n",
      "Epoch 279: train loss: 0.1576, test loss 0.4263\n",
      "Epoch 280: train loss: 0.1575, test loss 0.4246\n",
      "Epoch 281: train loss: 0.1574, test loss 0.4229\n",
      "Epoch 282: train loss: 0.1573, test loss 0.4212\n",
      "Epoch 283: train loss: 0.1572, test loss 0.4196\n",
      "Epoch 284: train loss: 0.1571, test loss 0.4179\n",
      "Epoch 285: train loss: 0.1570, test loss 0.4163\n",
      "Epoch 286: train loss: 0.1569, test loss 0.4147\n",
      "Epoch 287: train loss: 0.1568, test loss 0.4131\n",
      "Epoch 288: train loss: 0.1567, test loss 0.4115\n",
      "Epoch 289: train loss: 0.1566, test loss 0.4099\n",
      "Epoch 290: train loss: 0.1565, test loss 0.4084\n",
      "Epoch 291: train loss: 0.1564, test loss 0.4068\n",
      "Epoch 292: train loss: 0.1563, test loss 0.4052\n",
      "Epoch 293: train loss: 0.1562, test loss 0.4037\n",
      "Epoch 294: train loss: 0.1561, test loss 0.4022\n",
      "Epoch 295: train loss: 0.1560, test loss 0.4007\n",
      "Epoch 296: train loss: 0.1559, test loss 0.3992\n",
      "Epoch 297: train loss: 0.1558, test loss 0.3977\n",
      "Epoch 298: train loss: 0.1557, test loss 0.3962\n",
      "Epoch 299: train loss: 0.1556, test loss 0.3948\n",
      "Epoch 300: train loss: 0.1556, test loss 0.3933\n",
      "Epoch 301: train loss: 0.1555, test loss 0.3918\n",
      "Epoch 302: train loss: 0.1554, test loss 0.3903\n",
      "Epoch 303: train loss: 0.1553, test loss 0.3889\n",
      "Epoch 304: train loss: 0.1552, test loss 0.3875\n",
      "Epoch 305: train loss: 0.1551, test loss 0.3861\n",
      "Epoch 306: train loss: 0.1550, test loss 0.3847\n",
      "Epoch 307: train loss: 0.1550, test loss 0.3834\n",
      "Epoch 308: train loss: 0.1549, test loss 0.3821\n",
      "Epoch 309: train loss: 0.1548, test loss 0.3808\n",
      "Epoch 310: train loss: 0.1547, test loss 0.3795\n",
      "Epoch 311: train loss: 0.1546, test loss 0.3782\n",
      "Epoch 312: train loss: 0.1545, test loss 0.3769\n",
      "Epoch 313: train loss: 0.1545, test loss 0.3757\n",
      "Epoch 314: train loss: 0.1544, test loss 0.3744\n",
      "Epoch 315: train loss: 0.1543, test loss 0.3731\n",
      "Epoch 316: train loss: 0.1542, test loss 0.3719\n",
      "Epoch 317: train loss: 0.1541, test loss 0.3706\n",
      "Epoch 318: train loss: 0.1541, test loss 0.3694\n",
      "Epoch 319: train loss: 0.1540, test loss 0.3682\n",
      "Epoch 320: train loss: 0.1539, test loss 0.3669\n",
      "Epoch 321: train loss: 0.1538, test loss 0.3657\n",
      "Epoch 322: train loss: 0.1538, test loss 0.3645\n",
      "Epoch 323: train loss: 0.1537, test loss 0.3633\n",
      "Epoch 324: train loss: 0.1536, test loss 0.3621\n",
      "Epoch 325: train loss: 0.1535, test loss 0.3609\n",
      "Epoch 326: train loss: 0.1535, test loss 0.3598\n",
      "Epoch 327: train loss: 0.1534, test loss 0.3586\n",
      "Epoch 328: train loss: 0.1533, test loss 0.3574\n",
      "Epoch 329: train loss: 0.1532, test loss 0.3562\n",
      "Epoch 330: train loss: 0.1531, test loss 0.3551\n",
      "Epoch 331: train loss: 0.1531, test loss 0.3539\n",
      "Epoch 332: train loss: 0.1530, test loss 0.3528\n",
      "Epoch 333: train loss: 0.1529, test loss 0.3516\n",
      "Epoch 334: train loss: 0.1529, test loss 0.3505\n",
      "Epoch 335: train loss: 0.1528, test loss 0.3494\n",
      "Epoch 336: train loss: 0.1527, test loss 0.3482\n",
      "Epoch 337: train loss: 0.1526, test loss 0.3471\n",
      "Epoch 338: train loss: 0.1526, test loss 0.3460\n",
      "Epoch 339: train loss: 0.1525, test loss 0.3449\n",
      "Epoch 340: train loss: 0.1524, test loss 0.3437\n",
      "Epoch 341: train loss: 0.1524, test loss 0.3426\n",
      "Epoch 342: train loss: 0.1523, test loss 0.3415\n",
      "Epoch 343: train loss: 0.1522, test loss 0.3404\n",
      "Epoch 344: train loss: 0.1522, test loss 0.3394\n",
      "Epoch 345: train loss: 0.1521, test loss 0.3383\n",
      "Epoch 346: train loss: 0.1520, test loss 0.3372\n",
      "Epoch 347: train loss: 0.1520, test loss 0.3361\n",
      "Epoch 348: train loss: 0.1519, test loss 0.3350\n",
      "Epoch 349: train loss: 0.1518, test loss 0.3340\n",
      "Epoch 350: train loss: 0.1518, test loss 0.3329\n",
      "Epoch 351: train loss: 0.1517, test loss 0.3319\n",
      "Epoch 352: train loss: 0.1516, test loss 0.3308\n",
      "Epoch 353: train loss: 0.1516, test loss 0.3298\n",
      "Epoch 354: train loss: 0.1515, test loss 0.3287\n",
      "Epoch 355: train loss: 0.1515, test loss 0.3277\n",
      "Epoch 356: train loss: 0.1514, test loss 0.3267\n",
      "Epoch 357: train loss: 0.1513, test loss 0.3257\n",
      "Epoch 358: train loss: 0.1513, test loss 0.3247\n",
      "Epoch 359: train loss: 0.1512, test loss 0.3237\n",
      "Epoch 360: train loss: 0.1512, test loss 0.3226\n",
      "Epoch 361: train loss: 0.1511, test loss 0.3216\n",
      "Epoch 362: train loss: 0.1510, test loss 0.3206\n",
      "Epoch 363: train loss: 0.1510, test loss 0.3197\n",
      "Epoch 364: train loss: 0.1509, test loss 0.3187\n",
      "Epoch 365: train loss: 0.1509, test loss 0.3177\n",
      "Epoch 366: train loss: 0.1508, test loss 0.3167\n",
      "Epoch 367: train loss: 0.1507, test loss 0.3158\n",
      "Epoch 368: train loss: 0.1507, test loss 0.3148\n",
      "Epoch 369: train loss: 0.1506, test loss 0.3138\n",
      "Epoch 370: train loss: 0.1506, test loss 0.3129\n",
      "Epoch 371: train loss: 0.1505, test loss 0.3119\n",
      "Epoch 372: train loss: 0.1505, test loss 0.3110\n",
      "Epoch 373: train loss: 0.1504, test loss 0.3101\n",
      "Epoch 374: train loss: 0.1503, test loss 0.3091\n",
      "Epoch 375: train loss: 0.1503, test loss 0.3082\n",
      "Epoch 376: train loss: 0.1502, test loss 0.3073\n",
      "Epoch 377: train loss: 0.1502, test loss 0.3063\n",
      "Epoch 378: train loss: 0.1501, test loss 0.3054\n",
      "Epoch 379: train loss: 0.1500, test loss 0.3045\n",
      "Epoch 380: train loss: 0.1500, test loss 0.3035\n",
      "Epoch 381: train loss: 0.1499, test loss 0.3026\n",
      "Epoch 382: train loss: 0.1499, test loss 0.3017\n",
      "Epoch 383: train loss: 0.1498, test loss 0.3008\n",
      "Epoch 384: train loss: 0.1498, test loss 0.2998\n",
      "Epoch 385: train loss: 0.1497, test loss 0.2989\n",
      "Epoch 386: train loss: 0.1496, test loss 0.2980\n",
      "Epoch 387: train loss: 0.1496, test loss 0.2971\n",
      "Epoch 388: train loss: 0.1495, test loss 0.2961\n",
      "Epoch 389: train loss: 0.1495, test loss 0.2952\n",
      "Epoch 390: train loss: 0.1494, test loss 0.2943\n",
      "Epoch 391: train loss: 0.1494, test loss 0.2934\n",
      "Epoch 392: train loss: 0.1493, test loss 0.2925\n",
      "Epoch 393: train loss: 0.1492, test loss 0.2917\n",
      "Epoch 394: train loss: 0.1492, test loss 0.2909\n",
      "Epoch 395: train loss: 0.1491, test loss 0.2901\n",
      "Epoch 396: train loss: 0.1491, test loss 0.2893\n",
      "Epoch 397: train loss: 0.1490, test loss 0.2884\n",
      "Epoch 398: train loss: 0.1490, test loss 0.2875\n",
      "Epoch 399: train loss: 0.1489, test loss 0.2866\n",
      "Epoch 400: train loss: 0.1489, test loss 0.2857\n",
      "Epoch 401: train loss: 0.1488, test loss 0.2848\n",
      "Epoch 402: train loss: 0.1488, test loss 0.2840\n",
      "Epoch 403: train loss: 0.1487, test loss 0.2832\n",
      "Epoch 404: train loss: 0.1486, test loss 0.2825\n",
      "Epoch 405: train loss: 0.1486, test loss 0.2818\n",
      "Epoch 406: train loss: 0.1485, test loss 0.2810\n",
      "Epoch 407: train loss: 0.1485, test loss 0.2802\n",
      "Epoch 408: train loss: 0.1484, test loss 0.2794\n",
      "Epoch 409: train loss: 0.1484, test loss 0.2785\n",
      "Epoch 410: train loss: 0.1483, test loss 0.2777\n",
      "Epoch 411: train loss: 0.1483, test loss 0.2770\n",
      "Epoch 412: train loss: 0.1482, test loss 0.2762\n",
      "Epoch 413: train loss: 0.1482, test loss 0.2755\n",
      "Epoch 414: train loss: 0.1481, test loss 0.2748\n",
      "Epoch 415: train loss: 0.1481, test loss 0.2740\n",
      "Epoch 416: train loss: 0.1480, test loss 0.2733\n",
      "Epoch 417: train loss: 0.1480, test loss 0.2726\n",
      "Epoch 418: train loss: 0.1479, test loss 0.2718\n",
      "Epoch 419: train loss: 0.1479, test loss 0.2711\n",
      "Epoch 420: train loss: 0.1478, test loss 0.2704\n",
      "Epoch 421: train loss: 0.1478, test loss 0.2697\n",
      "Epoch 422: train loss: 0.1477, test loss 0.2691\n",
      "Epoch 423: train loss: 0.1477, test loss 0.2684\n",
      "Epoch 424: train loss: 0.1476, test loss 0.2677\n",
      "Epoch 425: train loss: 0.1476, test loss 0.2669\n",
      "Epoch 426: train loss: 0.1475, test loss 0.2662\n",
      "Epoch 427: train loss: 0.1475, test loss 0.2655\n",
      "Epoch 428: train loss: 0.1474, test loss 0.2648\n",
      "Epoch 429: train loss: 0.1474, test loss 0.2642\n",
      "Epoch 430: train loss: 0.1473, test loss 0.2635\n",
      "Epoch 431: train loss: 0.1473, test loss 0.2629\n",
      "Epoch 432: train loss: 0.1473, test loss 0.2623\n",
      "Epoch 433: train loss: 0.1472, test loss 0.2616\n",
      "Epoch 434: train loss: 0.1472, test loss 0.2609\n",
      "Epoch 435: train loss: 0.1471, test loss 0.2602\n",
      "Epoch 436: train loss: 0.1471, test loss 0.2596\n",
      "Epoch 437: train loss: 0.1470, test loss 0.2589\n",
      "Epoch 438: train loss: 0.1470, test loss 0.2583\n",
      "Epoch 439: train loss: 0.1469, test loss 0.2576\n",
      "Epoch 440: train loss: 0.1469, test loss 0.2569\n",
      "Epoch 441: train loss: 0.1468, test loss 0.2563\n",
      "Epoch 442: train loss: 0.1468, test loss 0.2556\n",
      "Epoch 443: train loss: 0.1467, test loss 0.2550\n",
      "Epoch 444: train loss: 0.1467, test loss 0.2544\n",
      "Epoch 445: train loss: 0.1467, test loss 0.2537\n",
      "Epoch 446: train loss: 0.1466, test loss 0.2531\n",
      "Epoch 447: train loss: 0.1466, test loss 0.2524\n",
      "Epoch 448: train loss: 0.1465, test loss 0.2518\n",
      "Epoch 449: train loss: 0.1465, test loss 0.2511\n",
      "Epoch 450: train loss: 0.1464, test loss 0.2505\n",
      "Epoch 451: train loss: 0.1464, test loss 0.2498\n",
      "Epoch 452: train loss: 0.1463, test loss 0.2492\n",
      "Epoch 453: train loss: 0.1463, test loss 0.2486\n",
      "Epoch 454: train loss: 0.1462, test loss 0.2480\n",
      "Epoch 455: train loss: 0.1462, test loss 0.2474\n",
      "Epoch 456: train loss: 0.1462, test loss 0.2467\n",
      "Epoch 457: train loss: 0.1461, test loss 0.2461\n",
      "Epoch 458: train loss: 0.1461, test loss 0.2456\n",
      "Epoch 459: train loss: 0.1460, test loss 0.2450\n",
      "Epoch 460: train loss: 0.1460, test loss 0.2444\n",
      "Epoch 461: train loss: 0.1459, test loss 0.2438\n",
      "Epoch 462: train loss: 0.1459, test loss 0.2432\n",
      "Epoch 463: train loss: 0.1459, test loss 0.2426\n",
      "Epoch 464: train loss: 0.1458, test loss 0.2420\n",
      "Epoch 465: train loss: 0.1458, test loss 0.2414\n",
      "Epoch 466: train loss: 0.1457, test loss 0.2408\n",
      "Epoch 467: train loss: 0.1457, test loss 0.2402\n",
      "Epoch 468: train loss: 0.1456, test loss 0.2397\n",
      "Epoch 469: train loss: 0.1456, test loss 0.2392\n",
      "Epoch 470: train loss: 0.1456, test loss 0.2386\n",
      "Epoch 471: train loss: 0.1455, test loss 0.2380\n",
      "Epoch 472: train loss: 0.1455, test loss 0.2374\n",
      "Epoch 473: train loss: 0.1454, test loss 0.2368\n",
      "Epoch 474: train loss: 0.1454, test loss 0.2363\n",
      "Epoch 475: train loss: 0.1454, test loss 0.2357\n",
      "Epoch 476: train loss: 0.1453, test loss 0.2352\n",
      "Epoch 477: train loss: 0.1453, test loss 0.2346\n",
      "Epoch 478: train loss: 0.1452, test loss 0.2341\n",
      "Epoch 479: train loss: 0.1452, test loss 0.2335\n",
      "Epoch 480: train loss: 0.1452, test loss 0.2329\n",
      "Epoch 481: train loss: 0.1451, test loss 0.2324\n",
      "Epoch 482: train loss: 0.1451, test loss 0.2319\n",
      "Epoch 483: train loss: 0.1450, test loss 0.2314\n",
      "Epoch 484: train loss: 0.1450, test loss 0.2309\n",
      "Epoch 485: train loss: 0.1450, test loss 0.2303\n",
      "Epoch 486: train loss: 0.1449, test loss 0.2297\n",
      "Epoch 487: train loss: 0.1449, test loss 0.2292\n",
      "Epoch 488: train loss: 0.1448, test loss 0.2286\n",
      "Epoch 489: train loss: 0.1448, test loss 0.2281\n",
      "Epoch 490: train loss: 0.1448, test loss 0.2277\n",
      "Epoch 491: train loss: 0.1447, test loss 0.2272\n",
      "Epoch 492: train loss: 0.1447, test loss 0.2267\n",
      "Epoch 493: train loss: 0.1446, test loss 0.2261\n",
      "Epoch 494: train loss: 0.1446, test loss 0.2256\n",
      "Epoch 495: train loss: 0.1446, test loss 0.2250\n",
      "Epoch 496: train loss: 0.1445, test loss 0.2244\n",
      "Epoch 497: train loss: 0.1445, test loss 0.2239\n",
      "Epoch 498: train loss: 0.1444, test loss 0.2234\n",
      "Epoch 499: train loss: 0.1444, test loss 0.2230\n",
      "Epoch 500: train loss: 0.1444, test loss 0.2226\n",
      "Epoch 501: train loss: 0.1443, test loss 0.2221\n",
      "Epoch 502: train loss: 0.1443, test loss 0.2216\n",
      "Epoch 503: train loss: 0.1442, test loss 0.2210\n",
      "Epoch 504: train loss: 0.1442, test loss 0.2204\n",
      "Epoch 505: train loss: 0.1442, test loss 0.2199\n",
      "Epoch 506: train loss: 0.1441, test loss 0.2194\n",
      "Epoch 507: train loss: 0.1441, test loss 0.2189\n",
      "Epoch 508: train loss: 0.1440, test loss 0.2185\n",
      "Epoch 509: train loss: 0.1440, test loss 0.2181\n",
      "Epoch 510: train loss: 0.1440, test loss 0.2177\n",
      "Epoch 511: train loss: 0.1439, test loss 0.2173\n",
      "Epoch 512: train loss: 0.1439, test loss 0.2168\n",
      "Epoch 513: train loss: 0.1439, test loss 0.2163\n",
      "Epoch 514: train loss: 0.1438, test loss 0.2158\n",
      "Epoch 515: train loss: 0.1438, test loss 0.2153\n",
      "Epoch 516: train loss: 0.1438, test loss 0.2149\n",
      "Epoch 517: train loss: 0.1437, test loss 0.2144\n",
      "Epoch 518: train loss: 0.1437, test loss 0.2140\n",
      "Epoch 519: train loss: 0.1437, test loss 0.2136\n",
      "Epoch 520: train loss: 0.1436, test loss 0.2132\n",
      "Epoch 521: train loss: 0.1436, test loss 0.2128\n",
      "Epoch 522: train loss: 0.1436, test loss 0.2123\n",
      "Epoch 523: train loss: 0.1435, test loss 0.2119\n",
      "Epoch 524: train loss: 0.1435, test loss 0.2114\n",
      "Epoch 525: train loss: 0.1435, test loss 0.2110\n",
      "Epoch 526: train loss: 0.1434, test loss 0.2106\n",
      "Epoch 527: train loss: 0.1434, test loss 0.2102\n",
      "Epoch 528: train loss: 0.1434, test loss 0.2098\n",
      "Epoch 529: train loss: 0.1433, test loss 0.2094\n",
      "Epoch 530: train loss: 0.1433, test loss 0.2090\n",
      "Epoch 531: train loss: 0.1433, test loss 0.2085\n",
      "Epoch 532: train loss: 0.1432, test loss 0.2081\n",
      "Epoch 533: train loss: 0.1432, test loss 0.2077\n",
      "Epoch 534: train loss: 0.1432, test loss 0.2074\n",
      "Epoch 535: train loss: 0.1431, test loss 0.2070\n",
      "Epoch 536: train loss: 0.1431, test loss 0.2066\n",
      "Epoch 537: train loss: 0.1431, test loss 0.2061\n",
      "Epoch 538: train loss: 0.1430, test loss 0.2056\n",
      "Epoch 539: train loss: 0.1430, test loss 0.2052\n",
      "Epoch 540: train loss: 0.1430, test loss 0.2048\n",
      "Epoch 541: train loss: 0.1430, test loss 0.2044\n",
      "Epoch 542: train loss: 0.1429, test loss 0.2041\n",
      "Epoch 543: train loss: 0.1429, test loss 0.2037\n",
      "Epoch 544: train loss: 0.1429, test loss 0.2034\n",
      "Epoch 545: train loss: 0.1428, test loss 0.2030\n",
      "Epoch 546: train loss: 0.1428, test loss 0.2025\n",
      "Epoch 547: train loss: 0.1428, test loss 0.2021\n",
      "Epoch 548: train loss: 0.1428, test loss 0.2016\n",
      "Epoch 549: train loss: 0.1427, test loss 0.2012\n",
      "Epoch 550: train loss: 0.1427, test loss 0.2009\n",
      "Epoch 551: train loss: 0.1427, test loss 0.2005\n",
      "Epoch 552: train loss: 0.1426, test loss 0.2002\n",
      "Epoch 553: train loss: 0.1426, test loss 0.1999\n",
      "Epoch 554: train loss: 0.1426, test loss 0.1995\n",
      "Epoch 555: train loss: 0.1425, test loss 0.1991\n",
      "Epoch 556: train loss: 0.1425, test loss 0.1987\n",
      "Epoch 557: train loss: 0.1425, test loss 0.1983\n",
      "Epoch 558: train loss: 0.1425, test loss 0.1979\n",
      "Epoch 559: train loss: 0.1424, test loss 0.1976\n",
      "Epoch 560: train loss: 0.1424, test loss 0.1972\n",
      "Epoch 561: train loss: 0.1424, test loss 0.1969\n",
      "Epoch 562: train loss: 0.1423, test loss 0.1965\n",
      "Epoch 563: train loss: 0.1423, test loss 0.1962\n",
      "Epoch 564: train loss: 0.1423, test loss 0.1958\n",
      "Epoch 565: train loss: 0.1423, test loss 0.1955\n",
      "Epoch 566: train loss: 0.1422, test loss 0.1951\n",
      "Epoch 567: train loss: 0.1422, test loss 0.1947\n",
      "Epoch 568: train loss: 0.1422, test loss 0.1943\n",
      "Epoch 569: train loss: 0.1421, test loss 0.1940\n",
      "Epoch 570: train loss: 0.1421, test loss 0.1936\n",
      "Epoch 571: train loss: 0.1421, test loss 0.1933\n",
      "Epoch 572: train loss: 0.1421, test loss 0.1930\n",
      "Epoch 573: train loss: 0.1420, test loss 0.1927\n",
      "Epoch 574: train loss: 0.1420, test loss 0.1923\n",
      "Epoch 575: train loss: 0.1420, test loss 0.1920\n",
      "Epoch 576: train loss: 0.1420, test loss 0.1916\n",
      "Epoch 577: train loss: 0.1419, test loss 0.1913\n",
      "Epoch 578: train loss: 0.1419, test loss 0.1910\n",
      "Epoch 579: train loss: 0.1419, test loss 0.1906\n",
      "Epoch 580: train loss: 0.1418, test loss 0.1903\n",
      "Epoch 581: train loss: 0.1418, test loss 0.1900\n",
      "Epoch 582: train loss: 0.1418, test loss 0.1897\n",
      "Epoch 583: train loss: 0.1418, test loss 0.1894\n",
      "Epoch 584: train loss: 0.1417, test loss 0.1891\n",
      "Epoch 585: train loss: 0.1417, test loss 0.1887\n",
      "Epoch 586: train loss: 0.1417, test loss 0.1884\n",
      "Epoch 587: train loss: 0.1417, test loss 0.1881\n",
      "Epoch 588: train loss: 0.1416, test loss 0.1878\n",
      "Epoch 589: train loss: 0.1416, test loss 0.1875\n",
      "Epoch 590: train loss: 0.1416, test loss 0.1872\n",
      "Epoch 591: train loss: 0.1415, test loss 0.1868\n",
      "Epoch 592: train loss: 0.1415, test loss 0.1865\n",
      "Epoch 593: train loss: 0.1415, test loss 0.1862\n",
      "Epoch 594: train loss: 0.1415, test loss 0.1859\n",
      "Epoch 595: train loss: 0.1414, test loss 0.1856\n",
      "Epoch 596: train loss: 0.1414, test loss 0.1853\n",
      "Epoch 597: train loss: 0.1414, test loss 0.1850\n",
      "Epoch 598: train loss: 0.1414, test loss 0.1847\n",
      "Epoch 599: train loss: 0.1413, test loss 0.1844\n",
      "Epoch 600: train loss: 0.1413, test loss 0.1841\n",
      "Epoch 601: train loss: 0.1413, test loss 0.1838\n",
      "Epoch 602: train loss: 0.1413, test loss 0.1835\n",
      "Epoch 603: train loss: 0.1412, test loss 0.1832\n",
      "Epoch 604: train loss: 0.1412, test loss 0.1829\n",
      "Epoch 605: train loss: 0.1412, test loss 0.1826\n",
      "Epoch 606: train loss: 0.1411, test loss 0.1824\n",
      "Epoch 607: train loss: 0.1411, test loss 0.1821\n",
      "Epoch 608: train loss: 0.1411, test loss 0.1818\n",
      "Epoch 609: train loss: 0.1411, test loss 0.1815\n",
      "Epoch 610: train loss: 0.1410, test loss 0.1812\n",
      "Epoch 611: train loss: 0.1410, test loss 0.1809\n",
      "Epoch 612: train loss: 0.1410, test loss 0.1806\n",
      "Epoch 613: train loss: 0.1410, test loss 0.1804\n",
      "Epoch 614: train loss: 0.1409, test loss 0.1801\n",
      "Epoch 615: train loss: 0.1409, test loss 0.1798\n",
      "Epoch 616: train loss: 0.1409, test loss 0.1795\n",
      "Epoch 617: train loss: 0.1409, test loss 0.1792\n",
      "Epoch 618: train loss: 0.1408, test loss 0.1789\n",
      "Epoch 619: train loss: 0.1408, test loss 0.1787\n",
      "Epoch 620: train loss: 0.1408, test loss 0.1784\n",
      "Epoch 621: train loss: 0.1408, test loss 0.1781\n",
      "Epoch 622: train loss: 0.1407, test loss 0.1779\n",
      "Epoch 623: train loss: 0.1407, test loss 0.1776\n",
      "Epoch 624: train loss: 0.1407, test loss 0.1773\n",
      "Epoch 625: train loss: 0.1406, test loss 0.1771\n",
      "Epoch 626: train loss: 0.1406, test loss 0.1768\n",
      "Epoch 627: train loss: 0.1406, test loss 0.1765\n",
      "Epoch 628: train loss: 0.1406, test loss 0.1762\n",
      "Epoch 629: train loss: 0.1405, test loss 0.1760\n",
      "Epoch 630: train loss: 0.1405, test loss 0.1758\n",
      "Epoch 631: train loss: 0.1405, test loss 0.1755\n",
      "Epoch 632: train loss: 0.1405, test loss 0.1753\n",
      "Epoch 633: train loss: 0.1404, test loss 0.1750\n",
      "Epoch 634: train loss: 0.1404, test loss 0.1747\n",
      "Epoch 635: train loss: 0.1404, test loss 0.1744\n",
      "Epoch 636: train loss: 0.1404, test loss 0.1742\n",
      "Epoch 637: train loss: 0.1403, test loss 0.1739\n",
      "Epoch 638: train loss: 0.1403, test loss 0.1737\n",
      "Epoch 639: train loss: 0.1403, test loss 0.1735\n",
      "Epoch 640: train loss: 0.1403, test loss 0.1732\n",
      "Epoch 641: train loss: 0.1402, test loss 0.1730\n",
      "Epoch 642: train loss: 0.1402, test loss 0.1727\n",
      "Epoch 643: train loss: 0.1402, test loss 0.1725\n",
      "Epoch 644: train loss: 0.1402, test loss 0.1722\n",
      "Epoch 645: train loss: 0.1401, test loss 0.1720\n",
      "Epoch 646: train loss: 0.1401, test loss 0.1717\n",
      "Epoch 647: train loss: 0.1401, test loss 0.1715\n",
      "Epoch 648: train loss: 0.1401, test loss 0.1712\n",
      "Epoch 649: train loss: 0.1400, test loss 0.1710\n",
      "Epoch 650: train loss: 0.1400, test loss 0.1708\n",
      "Epoch 651: train loss: 0.1400, test loss 0.1707\n",
      "Epoch 652: train loss: 0.1400, test loss 0.1704\n",
      "Epoch 653: train loss: 0.1399, test loss 0.1702\n",
      "Epoch 654: train loss: 0.1399, test loss 0.1700\n",
      "Epoch 655: train loss: 0.1399, test loss 0.1697\n",
      "Epoch 656: train loss: 0.1399, test loss 0.1695\n",
      "Epoch 657: train loss: 0.1398, test loss 0.1693\n",
      "Epoch 658: train loss: 0.1398, test loss 0.1692\n",
      "Epoch 659: train loss: 0.1398, test loss 0.1690\n",
      "Epoch 660: train loss: 0.1398, test loss 0.1688\n",
      "Epoch 661: train loss: 0.1398, test loss 0.1686\n",
      "Epoch 662: train loss: 0.1397, test loss 0.1684\n",
      "Epoch 663: train loss: 0.1397, test loss 0.1682\n",
      "Epoch 664: train loss: 0.1397, test loss 0.1680\n",
      "Epoch 665: train loss: 0.1397, test loss 0.1678\n",
      "Epoch 666: train loss: 0.1396, test loss 0.1676\n",
      "Epoch 667: train loss: 0.1396, test loss 0.1675\n",
      "Epoch 668: train loss: 0.1396, test loss 0.1673\n",
      "Epoch 669: train loss: 0.1396, test loss 0.1671\n",
      "Epoch 670: train loss: 0.1396, test loss 0.1669\n",
      "Epoch 671: train loss: 0.1395, test loss 0.1667\n",
      "Epoch 672: train loss: 0.1395, test loss 0.1665\n",
      "Epoch 673: train loss: 0.1395, test loss 0.1663\n",
      "Epoch 674: train loss: 0.1395, test loss 0.1661\n",
      "Epoch 675: train loss: 0.1394, test loss 0.1659\n",
      "Epoch 676: train loss: 0.1394, test loss 0.1657\n",
      "Epoch 677: train loss: 0.1394, test loss 0.1655\n",
      "Epoch 678: train loss: 0.1394, test loss 0.1653\n",
      "Epoch 679: train loss: 0.1393, test loss 0.1652\n",
      "Epoch 680: train loss: 0.1393, test loss 0.1650\n",
      "Epoch 681: train loss: 0.1393, test loss 0.1648\n",
      "Epoch 682: train loss: 0.1393, test loss 0.1645\n",
      "Epoch 683: train loss: 0.1393, test loss 0.1643\n",
      "Epoch 684: train loss: 0.1392, test loss 0.1641\n",
      "Epoch 685: train loss: 0.1392, test loss 0.1639\n",
      "Epoch 686: train loss: 0.1392, test loss 0.1637\n",
      "Epoch 687: train loss: 0.1392, test loss 0.1635\n",
      "Epoch 688: train loss: 0.1391, test loss 0.1634\n",
      "Epoch 689: train loss: 0.1391, test loss 0.1632\n",
      "Epoch 690: train loss: 0.1391, test loss 0.1630\n",
      "Epoch 691: train loss: 0.1391, test loss 0.1627\n",
      "Epoch 692: train loss: 0.1390, test loss 0.1625\n",
      "Epoch 693: train loss: 0.1390, test loss 0.1623\n",
      "Epoch 694: train loss: 0.1390, test loss 0.1622\n",
      "Epoch 695: train loss: 0.1390, test loss 0.1620\n",
      "Epoch 696: train loss: 0.1389, test loss 0.1618\n",
      "Epoch 697: train loss: 0.1389, test loss 0.1616\n",
      "Epoch 698: train loss: 0.1389, test loss 0.1614\n",
      "Epoch 699: train loss: 0.1389, test loss 0.1612\n",
      "Epoch 700: train loss: 0.1389, test loss 0.1610\n",
      "Epoch 701: train loss: 0.1388, test loss 0.1608\n",
      "Epoch 702: train loss: 0.1388, test loss 0.1606\n",
      "Epoch 703: train loss: 0.1388, test loss 0.1605\n",
      "Epoch 704: train loss: 0.1388, test loss 0.1603\n",
      "Epoch 705: train loss: 0.1387, test loss 0.1601\n",
      "Epoch 706: train loss: 0.1387, test loss 0.1599\n",
      "Epoch 707: train loss: 0.1387, test loss 0.1597\n",
      "Epoch 708: train loss: 0.1387, test loss 0.1595\n",
      "Epoch 709: train loss: 0.1387, test loss 0.1593\n",
      "Epoch 710: train loss: 0.1386, test loss 0.1591\n",
      "Epoch 711: train loss: 0.1386, test loss 0.1589\n",
      "Epoch 712: train loss: 0.1386, test loss 0.1588\n",
      "Epoch 713: train loss: 0.1386, test loss 0.1586\n",
      "Epoch 714: train loss: 0.1386, test loss 0.1584\n",
      "Epoch 715: train loss: 0.1385, test loss 0.1582\n",
      "Epoch 716: train loss: 0.1385, test loss 0.1580\n",
      "Epoch 717: train loss: 0.1385, test loss 0.1578\n",
      "Epoch 718: train loss: 0.1385, test loss 0.1576\n",
      "Epoch 719: train loss: 0.1384, test loss 0.1574\n",
      "Epoch 720: train loss: 0.1384, test loss 0.1572\n",
      "Epoch 721: train loss: 0.1384, test loss 0.1570\n",
      "Epoch 722: train loss: 0.1384, test loss 0.1569\n",
      "Epoch 723: train loss: 0.1384, test loss 0.1567\n",
      "Epoch 724: train loss: 0.1383, test loss 0.1565\n",
      "Epoch 725: train loss: 0.1383, test loss 0.1563\n",
      "Epoch 726: train loss: 0.1383, test loss 0.1562\n",
      "Epoch 727: train loss: 0.1383, test loss 0.1560\n",
      "Epoch 728: train loss: 0.1383, test loss 0.1558\n",
      "Epoch 729: train loss: 0.1382, test loss 0.1556\n",
      "Epoch 730: train loss: 0.1382, test loss 0.1554\n",
      "Epoch 731: train loss: 0.1382, test loss 0.1552\n",
      "Epoch 732: train loss: 0.1382, test loss 0.1551\n",
      "Epoch 733: train loss: 0.1381, test loss 0.1549\n",
      "Epoch 734: train loss: 0.1381, test loss 0.1547\n",
      "Epoch 735: train loss: 0.1381, test loss 0.1546\n",
      "Epoch 736: train loss: 0.1381, test loss 0.1544\n",
      "Epoch 737: train loss: 0.1381, test loss 0.1542\n",
      "Epoch 738: train loss: 0.1380, test loss 0.1540\n",
      "Epoch 739: train loss: 0.1380, test loss 0.1539\n",
      "Epoch 740: train loss: 0.1380, test loss 0.1537\n",
      "Epoch 741: train loss: 0.1380, test loss 0.1535\n",
      "Epoch 742: train loss: 0.1380, test loss 0.1534\n",
      "Epoch 743: train loss: 0.1379, test loss 0.1532\n",
      "Epoch 744: train loss: 0.1379, test loss 0.1530\n",
      "Epoch 745: train loss: 0.1379, test loss 0.1529\n",
      "Epoch 746: train loss: 0.1379, test loss 0.1527\n",
      "Epoch 747: train loss: 0.1379, test loss 0.1525\n",
      "Epoch 748: train loss: 0.1378, test loss 0.1524\n",
      "Epoch 749: train loss: 0.1378, test loss 0.1522\n",
      "Epoch 750: train loss: 0.1378, test loss 0.1521\n",
      "Epoch 751: train loss: 0.1378, test loss 0.1520\n",
      "Epoch 752: train loss: 0.1378, test loss 0.1518\n",
      "Epoch 753: train loss: 0.1377, test loss 0.1516\n",
      "Epoch 754: train loss: 0.1377, test loss 0.1515\n",
      "Epoch 755: train loss: 0.1377, test loss 0.1513\n",
      "Epoch 756: train loss: 0.1377, test loss 0.1512\n",
      "Epoch 757: train loss: 0.1377, test loss 0.1511\n",
      "Epoch 758: train loss: 0.1376, test loss 0.1509\n",
      "Epoch 759: train loss: 0.1376, test loss 0.1508\n",
      "Epoch 760: train loss: 0.1376, test loss 0.1506\n",
      "Epoch 761: train loss: 0.1376, test loss 0.1505\n",
      "Epoch 762: train loss: 0.1376, test loss 0.1504\n",
      "Epoch 763: train loss: 0.1375, test loss 0.1502\n",
      "Epoch 764: train loss: 0.1375, test loss 0.1501\n",
      "Epoch 765: train loss: 0.1375, test loss 0.1500\n",
      "Epoch 766: train loss: 0.1375, test loss 0.1498\n",
      "Epoch 767: train loss: 0.1375, test loss 0.1497\n",
      "Epoch 768: train loss: 0.1374, test loss 0.1495\n",
      "Epoch 769: train loss: 0.1374, test loss 0.1494\n",
      "Epoch 770: train loss: 0.1374, test loss 0.1493\n",
      "Epoch 771: train loss: 0.1374, test loss 0.1492\n",
      "Epoch 772: train loss: 0.1374, test loss 0.1490\n",
      "Epoch 773: train loss: 0.1373, test loss 0.1489\n",
      "Epoch 774: train loss: 0.1373, test loss 0.1488\n",
      "Epoch 775: train loss: 0.1373, test loss 0.1486\n",
      "Epoch 776: train loss: 0.1373, test loss 0.1485\n",
      "Epoch 777: train loss: 0.1373, test loss 0.1483\n",
      "Epoch 778: train loss: 0.1372, test loss 0.1482\n",
      "Epoch 779: train loss: 0.1372, test loss 0.1481\n",
      "Epoch 780: train loss: 0.1372, test loss 0.1480\n",
      "Epoch 781: train loss: 0.1372, test loss 0.1479\n",
      "Epoch 782: train loss: 0.1372, test loss 0.1478\n",
      "Epoch 783: train loss: 0.1372, test loss 0.1476\n",
      "Epoch 784: train loss: 0.1371, test loss 0.1475\n",
      "Epoch 785: train loss: 0.1371, test loss 0.1474\n",
      "Epoch 786: train loss: 0.1371, test loss 0.1472\n",
      "Epoch 787: train loss: 0.1371, test loss 0.1471\n",
      "Epoch 788: train loss: 0.1371, test loss 0.1470\n",
      "Epoch 789: train loss: 0.1370, test loss 0.1469\n",
      "Epoch 790: train loss: 0.1370, test loss 0.1469\n",
      "Epoch 791: train loss: 0.1370, test loss 0.1468\n",
      "Epoch 792: train loss: 0.1370, test loss 0.1466\n",
      "Epoch 793: train loss: 0.1370, test loss 0.1465\n",
      "Epoch 794: train loss: 0.1370, test loss 0.1464\n",
      "Epoch 795: train loss: 0.1369, test loss 0.1463\n",
      "Epoch 796: train loss: 0.1369, test loss 0.1462\n",
      "Epoch 797: train loss: 0.1369, test loss 0.1461\n",
      "Epoch 798: train loss: 0.1369, test loss 0.1460\n",
      "Epoch 799: train loss: 0.1369, test loss 0.1459\n",
      "Epoch 800: train loss: 0.1368, test loss 0.1457\n",
      "Epoch 801: train loss: 0.1368, test loss 0.1456\n",
      "Epoch 802: train loss: 0.1368, test loss 0.1455\n",
      "Epoch 803: train loss: 0.1368, test loss 0.1454\n",
      "Epoch 804: train loss: 0.1368, test loss 0.1453\n",
      "Epoch 805: train loss: 0.1368, test loss 0.1452\n",
      "Epoch 806: train loss: 0.1367, test loss 0.1451\n",
      "Epoch 807: train loss: 0.1367, test loss 0.1450\n",
      "Epoch 808: train loss: 0.1367, test loss 0.1449\n",
      "Epoch 809: train loss: 0.1367, test loss 0.1449\n",
      "Epoch 810: train loss: 0.1367, test loss 0.1448\n",
      "Epoch 811: train loss: 0.1367, test loss 0.1447\n",
      "Epoch 812: train loss: 0.1366, test loss 0.1446\n",
      "Epoch 813: train loss: 0.1366, test loss 0.1445\n",
      "Epoch 814: train loss: 0.1366, test loss 0.1444\n",
      "Epoch 815: train loss: 0.1366, test loss 0.1443\n",
      "Epoch 816: train loss: 0.1366, test loss 0.1442\n",
      "Epoch 817: train loss: 0.1365, test loss 0.1441\n",
      "Epoch 818: train loss: 0.1365, test loss 0.1440\n",
      "Epoch 819: train loss: 0.1365, test loss 0.1439\n",
      "Epoch 820: train loss: 0.1365, test loss 0.1438\n",
      "Epoch 821: train loss: 0.1365, test loss 0.1437\n",
      "Epoch 822: train loss: 0.1365, test loss 0.1436\n",
      "Epoch 823: train loss: 0.1364, test loss 0.1435\n",
      "Epoch 824: train loss: 0.1364, test loss 0.1434\n",
      "Epoch 825: train loss: 0.1364, test loss 0.1433\n",
      "Epoch 826: train loss: 0.1364, test loss 0.1432\n",
      "Epoch 827: train loss: 0.1364, test loss 0.1431\n",
      "Epoch 828: train loss: 0.1363, test loss 0.1430\n",
      "Epoch 829: train loss: 0.1363, test loss 0.1429\n",
      "Epoch 830: train loss: 0.1363, test loss 0.1428\n",
      "Epoch 831: train loss: 0.1363, test loss 0.1427\n",
      "Epoch 832: train loss: 0.1363, test loss 0.1426\n",
      "Epoch 833: train loss: 0.1363, test loss 0.1425\n",
      "Epoch 834: train loss: 0.1362, test loss 0.1424\n",
      "Epoch 835: train loss: 0.1362, test loss 0.1423\n",
      "Epoch 836: train loss: 0.1362, test loss 0.1422\n",
      "Epoch 837: train loss: 0.1362, test loss 0.1421\n",
      "Epoch 838: train loss: 0.1362, test loss 0.1420\n",
      "Epoch 839: train loss: 0.1361, test loss 0.1419\n",
      "Epoch 840: train loss: 0.1361, test loss 0.1418\n",
      "Epoch 841: train loss: 0.1361, test loss 0.1417\n",
      "Epoch 842: train loss: 0.1361, test loss 0.1416\n",
      "Epoch 843: train loss: 0.1361, test loss 0.1415\n",
      "Epoch 844: train loss: 0.1361, test loss 0.1414\n",
      "Epoch 845: train loss: 0.1360, test loss 0.1413\n",
      "Epoch 846: train loss: 0.1360, test loss 0.1413\n",
      "Epoch 847: train loss: 0.1360, test loss 0.1412\n",
      "Epoch 848: train loss: 0.1360, test loss 0.1411\n",
      "Epoch 849: train loss: 0.1360, test loss 0.1410\n",
      "Epoch 850: train loss: 0.1359, test loss 0.1409\n",
      "Epoch 851: train loss: 0.1359, test loss 0.1408\n",
      "Epoch 852: train loss: 0.1359, test loss 0.1407\n",
      "Epoch 853: train loss: 0.1359, test loss 0.1407\n",
      "Epoch 854: train loss: 0.1359, test loss 0.1406\n",
      "Epoch 855: train loss: 0.1358, test loss 0.1405\n",
      "Epoch 856: train loss: 0.1358, test loss 0.1404\n",
      "Epoch 857: train loss: 0.1358, test loss 0.1403\n",
      "Epoch 858: train loss: 0.1358, test loss 0.1402\n",
      "Epoch 859: train loss: 0.1358, test loss 0.1402\n",
      "Epoch 860: train loss: 0.1358, test loss 0.1401\n",
      "Epoch 861: train loss: 0.1357, test loss 0.1400\n",
      "Epoch 862: train loss: 0.1357, test loss 0.1400\n",
      "Epoch 863: train loss: 0.1357, test loss 0.1399\n",
      "Epoch 864: train loss: 0.1357, test loss 0.1398\n",
      "Epoch 865: train loss: 0.1357, test loss 0.1398\n",
      "Epoch 866: train loss: 0.1356, test loss 0.1397\n",
      "Epoch 867: train loss: 0.1356, test loss 0.1396\n",
      "Epoch 868: train loss: 0.1356, test loss 0.1395\n",
      "Epoch 869: train loss: 0.1356, test loss 0.1394\n",
      "Epoch 870: train loss: 0.1356, test loss 0.1393\n",
      "Epoch 871: train loss: 0.1355, test loss 0.1393\n",
      "Epoch 872: train loss: 0.1355, test loss 0.1392\n",
      "Epoch 873: train loss: 0.1355, test loss 0.1392\n",
      "Epoch 874: train loss: 0.1355, test loss 0.1391\n",
      "Epoch 875: train loss: 0.1354, test loss 0.1390\n",
      "Epoch 876: train loss: 0.1354, test loss 0.1389\n",
      "Epoch 877: train loss: 0.1354, test loss 0.1388\n",
      "Epoch 878: train loss: 0.1354, test loss 0.1388\n",
      "Epoch 879: train loss: 0.1354, test loss 0.1387\n",
      "Epoch 880: train loss: 0.1353, test loss 0.1386\n",
      "Epoch 881: train loss: 0.1353, test loss 0.1386\n",
      "Epoch 882: train loss: 0.1353, test loss 0.1385\n",
      "Epoch 883: train loss: 0.1353, test loss 0.1384\n",
      "Epoch 884: train loss: 0.1353, test loss 0.1384\n",
      "Epoch 885: train loss: 0.1352, test loss 0.1383\n",
      "Epoch 886: train loss: 0.1352, test loss 0.1382\n",
      "Epoch 887: train loss: 0.1352, test loss 0.1382\n",
      "Epoch 888: train loss: 0.1352, test loss 0.1381\n",
      "Epoch 889: train loss: 0.1352, test loss 0.1380\n",
      "Epoch 890: train loss: 0.1351, test loss 0.1380\n",
      "Epoch 891: train loss: 0.1351, test loss 0.1379\n",
      "Epoch 892: train loss: 0.1351, test loss 0.1378\n",
      "Epoch 893: train loss: 0.1351, test loss 0.1378\n",
      "Epoch 894: train loss: 0.1351, test loss 0.1377\n",
      "Epoch 895: train loss: 0.1350, test loss 0.1377\n",
      "Epoch 896: train loss: 0.1350, test loss 0.1376\n",
      "Epoch 897: train loss: 0.1350, test loss 0.1375\n",
      "Epoch 898: train loss: 0.1350, test loss 0.1374\n",
      "Epoch 899: train loss: 0.1349, test loss 0.1374\n",
      "Epoch 900: train loss: 0.1349, test loss 0.1373\n",
      "Epoch 901: train loss: 0.1349, test loss 0.1373\n",
      "Epoch 902: train loss: 0.1349, test loss 0.1372\n",
      "Epoch 903: train loss: 0.1349, test loss 0.1372\n",
      "Epoch 904: train loss: 0.1348, test loss 0.1372\n",
      "Epoch 905: train loss: 0.1348, test loss 0.1371\n",
      "Epoch 906: train loss: 0.1348, test loss 0.1371\n",
      "Epoch 907: train loss: 0.1348, test loss 0.1370\n",
      "Epoch 908: train loss: 0.1347, test loss 0.1369\n",
      "Epoch 909: train loss: 0.1347, test loss 0.1369\n",
      "Epoch 910: train loss: 0.1347, test loss 0.1368\n",
      "Epoch 911: train loss: 0.1347, test loss 0.1368\n",
      "Epoch 912: train loss: 0.1346, test loss 0.1368\n",
      "Epoch 913: train loss: 0.1346, test loss 0.1368\n",
      "Epoch 914: train loss: 0.1346, test loss 0.1368\n",
      "Epoch 915: train loss: 0.1346, test loss 0.1367\n",
      "Epoch 916: train loss: 0.1345, test loss 0.1367\n",
      "Epoch 917: train loss: 0.1345, test loss 0.1367\n",
      "Epoch 918: train loss: 0.1345, test loss 0.1366\n",
      "Epoch 919: train loss: 0.1345, test loss 0.1366\n",
      "Epoch 920: train loss: 0.1344, test loss 0.1366\n",
      "Epoch 921: train loss: 0.1344, test loss 0.1366\n",
      "Epoch 922: train loss: 0.1344, test loss 0.1366\n",
      "Epoch 923: train loss: 0.1344, test loss 0.1366\n",
      "Epoch 924: train loss: 0.1343, test loss 0.1366\n",
      "Epoch 925: train loss: 0.1343, test loss 0.1365\n",
      "Epoch 926: train loss: 0.1343, test loss 0.1365\n",
      "Epoch 927: train loss: 0.1342, test loss 0.1365\n",
      "Epoch 928: train loss: 0.1342, test loss 0.1365\n",
      "Epoch 929: train loss: 0.1342, test loss 0.1365\n",
      "Epoch 930: train loss: 0.1341, test loss 0.1366\n",
      "Epoch 931: train loss: 0.1341, test loss 0.1366\n",
      "Epoch 932: train loss: 0.1340, test loss 0.1367\n",
      "Epoch 933: train loss: 0.1340, test loss 0.1367\n",
      "Epoch 934: train loss: 0.1340, test loss 0.1367\n",
      "Epoch 935: train loss: 0.1339, test loss 0.1368\n",
      "Epoch 936: train loss: 0.1338, test loss 0.1368\n",
      "Epoch 937: train loss: 0.1338, test loss 0.1369\n",
      "Epoch 938: train loss: 0.1337, test loss 0.1370\n",
      "Epoch 939: train loss: 0.1336, test loss 0.1372\n",
      "Epoch 940: train loss: 0.1336, test loss 0.1373\n",
      "Epoch 941: train loss: 0.1335, test loss 0.1374\n",
      "Epoch 942: train loss: 0.1334, test loss 0.1375\n",
      "Epoch 943: train loss: 0.1334, test loss 0.1376\n",
      "Epoch 944: train loss: 0.1333, test loss 0.1378\n",
      "Epoch 945: train loss: 0.1332, test loss 0.1379\n",
      "Epoch 946: train loss: 0.1332, test loss 0.1380\n",
      "Epoch 947: train loss: 0.1331, test loss 0.1382\n",
      "Epoch 948: train loss: 0.1331, test loss 0.1383\n",
      "Epoch 949: train loss: 0.1330, test loss 0.1384\n",
      "Epoch 950: train loss: 0.1330, test loss 0.1385\n",
      "Epoch 951: train loss: 0.1329, test loss 0.1386\n",
      "Epoch 952: train loss: 0.1329, test loss 0.1387\n",
      "Epoch 953: train loss: 0.1328, test loss 0.1389\n",
      "Epoch 954: train loss: 0.1328, test loss 0.1390\n",
      "Epoch 955: train loss: 0.1327, test loss 0.1390\n",
      "Epoch 956: train loss: 0.1327, test loss 0.1391\n",
      "Epoch 957: train loss: 0.1326, test loss 0.1392\n",
      "Epoch 958: train loss: 0.1325, test loss 0.1392\n",
      "Epoch 959: train loss: 0.1325, test loss 0.1392\n",
      "Epoch 960: train loss: 0.1324, test loss 0.1393\n",
      "Epoch 961: train loss: 0.1324, test loss 0.1393\n",
      "Epoch 962: train loss: 0.1324, test loss 0.1393\n",
      "Epoch 963: train loss: 0.1323, test loss 0.1393\n",
      "Epoch 964: train loss: 0.1323, test loss 0.1393\n",
      "Epoch 965: train loss: 0.1322, test loss 0.1393\n",
      "Epoch 966: train loss: 0.1322, test loss 0.1392\n",
      "Epoch 967: train loss: 0.1321, test loss 0.1392\n",
      "Epoch 968: train loss: 0.1321, test loss 0.1392\n",
      "Epoch 969: train loss: 0.1321, test loss 0.1392\n",
      "Epoch 970: train loss: 0.1320, test loss 0.1391\n",
      "Epoch 971: train loss: 0.1320, test loss 0.1391\n",
      "Epoch 972: train loss: 0.1319, test loss 0.1390\n",
      "Epoch 973: train loss: 0.1319, test loss 0.1389\n",
      "Epoch 974: train loss: 0.1319, test loss 0.1389\n",
      "Epoch 975: train loss: 0.1318, test loss 0.1388\n",
      "Epoch 976: train loss: 0.1318, test loss 0.1388\n",
      "Epoch 977: train loss: 0.1318, test loss 0.1387\n",
      "Epoch 978: train loss: 0.1317, test loss 0.1387\n",
      "Epoch 979: train loss: 0.1317, test loss 0.1386\n",
      "Epoch 980: train loss: 0.1317, test loss 0.1386\n",
      "Epoch 981: train loss: 0.1316, test loss 0.1385\n",
      "Epoch 982: train loss: 0.1316, test loss 0.1384\n",
      "Epoch 983: train loss: 0.1316, test loss 0.1383\n",
      "Epoch 984: train loss: 0.1316, test loss 0.1383\n",
      "Epoch 985: train loss: 0.1315, test loss 0.1383\n",
      "Epoch 986: train loss: 0.1315, test loss 0.1382\n",
      "Epoch 987: train loss: 0.1315, test loss 0.1381\n",
      "Epoch 988: train loss: 0.1314, test loss 0.1379\n",
      "Epoch 989: train loss: 0.1314, test loss 0.1378\n",
      "Epoch 990: train loss: 0.1314, test loss 0.1378\n",
      "Epoch 991: train loss: 0.1313, test loss 0.1378\n",
      "Epoch 992: train loss: 0.1313, test loss 0.1377\n",
      "Epoch 993: train loss: 0.1313, test loss 0.1377\n",
      "Epoch 994: train loss: 0.1313, test loss 0.1376\n",
      "Epoch 995: train loss: 0.1312, test loss 0.1375\n",
      "Epoch 996: train loss: 0.1312, test loss 0.1374\n",
      "Epoch 997: train loss: 0.1312, test loss 0.1374\n",
      "Epoch 998: train loss: 0.1312, test loss 0.1374\n",
      "Epoch 999: train loss: 0.1311, test loss 0.1373\n",
      "Epoch 1000: train loss: 0.1311, test loss 0.1372\n",
      "Epoch 1001: train loss: 0.1311, test loss 0.1372\n",
      "Epoch 1002: train loss: 0.1310, test loss 0.1371\n",
      "Epoch 1003: train loss: 0.1310, test loss 0.1371\n",
      "Epoch 1004: train loss: 0.1310, test loss 0.1371\n",
      "Epoch 1005: train loss: 0.1310, test loss 0.1371\n",
      "Epoch 1006: train loss: 0.1309, test loss 0.1370\n",
      "Epoch 1007: train loss: 0.1309, test loss 0.1369\n",
      "Epoch 1008: train loss: 0.1309, test loss 0.1369\n",
      "Epoch 1009: train loss: 0.1309, test loss 0.1368\n",
      "Epoch 1010: train loss: 0.1308, test loss 0.1368\n",
      "Epoch 1011: train loss: 0.1308, test loss 0.1368\n",
      "Epoch 1012: train loss: 0.1308, test loss 0.1368\n",
      "Epoch 1013: train loss: 0.1308, test loss 0.1368\n",
      "Epoch 1014: train loss: 0.1307, test loss 0.1367\n",
      "Epoch 1015: train loss: 0.1307, test loss 0.1366\n",
      "Epoch 1016: train loss: 0.1307, test loss 0.1366\n",
      "Epoch 1017: train loss: 0.1307, test loss 0.1367\n",
      "Epoch 1018: train loss: 0.1306, test loss 0.1367\n",
      "Epoch 1019: train loss: 0.1306, test loss 0.1366\n",
      "Epoch 1020: train loss: 0.1306, test loss 0.1365\n",
      "Epoch 1021: train loss: 0.1306, test loss 0.1364\n",
      "Epoch 1022: train loss: 0.1305, test loss 0.1364\n",
      "Epoch 1023: train loss: 0.1305, test loss 0.1364\n",
      "Epoch 1024: train loss: 0.1305, test loss 0.1364\n",
      "Epoch 1025: train loss: 0.1305, test loss 0.1364\n",
      "Epoch 1026: train loss: 0.1304, test loss 0.1364\n",
      "Epoch 1027: train loss: 0.1304, test loss 0.1363\n",
      "Epoch 1028: train loss: 0.1304, test loss 0.1362\n",
      "Epoch 1029: train loss: 0.1304, test loss 0.1362\n",
      "Epoch 1030: train loss: 0.1303, test loss 0.1362\n",
      "Epoch 1031: train loss: 0.1303, test loss 0.1362\n",
      "Epoch 1032: train loss: 0.1303, test loss 0.1362\n",
      "Epoch 1033: train loss: 0.1303, test loss 0.1361\n",
      "Epoch 1034: train loss: 0.1302, test loss 0.1361\n",
      "Epoch 1035: train loss: 0.1302, test loss 0.1361\n",
      "Epoch 1036: train loss: 0.1302, test loss 0.1360\n",
      "Epoch 1037: train loss: 0.1302, test loss 0.1360\n",
      "Epoch 1038: train loss: 0.1301, test loss 0.1360\n",
      "Epoch 1039: train loss: 0.1301, test loss 0.1360\n",
      "Epoch 1040: train loss: 0.1301, test loss 0.1360\n",
      "Epoch 1041: train loss: 0.1301, test loss 0.1360\n",
      "Epoch 1042: train loss: 0.1301, test loss 0.1360\n",
      "Epoch 1043: train loss: 0.1300, test loss 0.1360\n",
      "Epoch 1044: train loss: 0.1300, test loss 0.1359\n",
      "Epoch 1045: train loss: 0.1300, test loss 0.1359\n",
      "Epoch 1046: train loss: 0.1300, test loss 0.1359\n",
      "Epoch 1047: train loss: 0.1299, test loss 0.1359\n",
      "Epoch 1048: train loss: 0.1299, test loss 0.1359\n",
      "Epoch 1049: train loss: 0.1299, test loss 0.1358\n",
      "Epoch 1050: train loss: 0.1299, test loss 0.1358\n",
      "Epoch 1051: train loss: 0.1299, test loss 0.1358\n",
      "Epoch 1052: train loss: 0.1298, test loss 0.1358\n",
      "Epoch 1053: train loss: 0.1298, test loss 0.1358\n",
      "Epoch 1054: train loss: 0.1298, test loss 0.1358\n",
      "Epoch 1055: train loss: 0.1298, test loss 0.1357\n",
      "Epoch 1056: train loss: 0.1298, test loss 0.1356\n",
      "Epoch 1057: train loss: 0.1297, test loss 0.1356\n",
      "Epoch 1058: train loss: 0.1297, test loss 0.1355\n",
      "Epoch 1059: train loss: 0.1297, test loss 0.1355\n",
      "Epoch 1060: train loss: 0.1297, test loss 0.1355\n",
      "Epoch 1061: train loss: 0.1297, test loss 0.1355\n",
      "Epoch 1062: train loss: 0.1296, test loss 0.1355\n",
      "Epoch 1063: train loss: 0.1296, test loss 0.1354\n",
      "Epoch 1064: train loss: 0.1296, test loss 0.1354\n",
      "Epoch 1065: train loss: 0.1296, test loss 0.1354\n",
      "Epoch 1066: train loss: 0.1296, test loss 0.1354\n",
      "Epoch 1067: train loss: 0.1295, test loss 0.1354\n",
      "Epoch 1068: train loss: 0.1295, test loss 0.1354\n",
      "Epoch 1069: train loss: 0.1295, test loss 0.1353\n",
      "Epoch 1070: train loss: 0.1295, test loss 0.1353\n",
      "Epoch 1071: train loss: 0.1295, test loss 0.1353\n",
      "Epoch 1072: train loss: 0.1295, test loss 0.1353\n",
      "Epoch 1073: train loss: 0.1294, test loss 0.1352\n",
      "Epoch 1074: train loss: 0.1294, test loss 0.1352\n",
      "Epoch 1075: train loss: 0.1294, test loss 0.1352\n",
      "Epoch 1076: train loss: 0.1294, test loss 0.1351\n",
      "Epoch 1077: train loss: 0.1294, test loss 0.1351\n",
      "Epoch 1078: train loss: 0.1293, test loss 0.1350\n",
      "Epoch 1079: train loss: 0.1293, test loss 0.1350\n",
      "Epoch 1080: train loss: 0.1293, test loss 0.1350\n",
      "Epoch 1081: train loss: 0.1293, test loss 0.1349\n",
      "Epoch 1082: train loss: 0.1293, test loss 0.1349\n",
      "Epoch 1083: train loss: 0.1293, test loss 0.1348\n",
      "Epoch 1084: train loss: 0.1292, test loss 0.1348\n",
      "Epoch 1085: train loss: 0.1292, test loss 0.1347\n",
      "Epoch 1086: train loss: 0.1292, test loss 0.1347\n",
      "Epoch 1087: train loss: 0.1292, test loss 0.1347\n",
      "Epoch 1088: train loss: 0.1292, test loss 0.1347\n",
      "Epoch 1089: train loss: 0.1292, test loss 0.1346\n",
      "Epoch 1090: train loss: 0.1291, test loss 0.1346\n",
      "Epoch 1091: train loss: 0.1291, test loss 0.1345\n",
      "Epoch 1092: train loss: 0.1291, test loss 0.1345\n",
      "Epoch 1093: train loss: 0.1291, test loss 0.1345\n",
      "Epoch 1094: train loss: 0.1291, test loss 0.1344\n",
      "Epoch 1095: train loss: 0.1291, test loss 0.1343\n",
      "Epoch 1096: train loss: 0.1290, test loss 0.1343\n",
      "Epoch 1097: train loss: 0.1290, test loss 0.1343\n",
      "Epoch 1098: train loss: 0.1290, test loss 0.1343\n",
      "Epoch 1099: train loss: 0.1290, test loss 0.1343\n",
      "Epoch 1100: train loss: 0.1290, test loss 0.1342\n",
      "Epoch 1101: train loss: 0.1290, test loss 0.1341\n",
      "Epoch 1102: train loss: 0.1289, test loss 0.1340\n",
      "Epoch 1103: train loss: 0.1289, test loss 0.1340\n",
      "Epoch 1104: train loss: 0.1289, test loss 0.1340\n",
      "Epoch 1105: train loss: 0.1289, test loss 0.1340\n",
      "Epoch 1106: train loss: 0.1289, test loss 0.1339\n",
      "Epoch 1107: train loss: 0.1289, test loss 0.1339\n",
      "Epoch 1108: train loss: 0.1288, test loss 0.1338\n",
      "Epoch 1109: train loss: 0.1288, test loss 0.1338\n",
      "Epoch 1110: train loss: 0.1288, test loss 0.1337\n",
      "Epoch 1111: train loss: 0.1288, test loss 0.1337\n",
      "Epoch 1112: train loss: 0.1288, test loss 0.1337\n",
      "Epoch 1113: train loss: 0.1288, test loss 0.1337\n",
      "Epoch 1114: train loss: 0.1287, test loss 0.1337\n",
      "Epoch 1115: train loss: 0.1287, test loss 0.1336\n",
      "Epoch 1116: train loss: 0.1287, test loss 0.1335\n",
      "Epoch 1117: train loss: 0.1287, test loss 0.1334\n",
      "Epoch 1118: train loss: 0.1287, test loss 0.1334\n",
      "Epoch 1119: train loss: 0.1287, test loss 0.1334\n",
      "Epoch 1120: train loss: 0.1287, test loss 0.1334\n",
      "Epoch 1121: train loss: 0.1286, test loss 0.1334\n",
      "Epoch 1122: train loss: 0.1286, test loss 0.1334\n",
      "Epoch 1123: train loss: 0.1286, test loss 0.1333\n",
      "Epoch 1124: train loss: 0.1286, test loss 0.1333\n",
      "Epoch 1125: train loss: 0.1286, test loss 0.1332\n",
      "Epoch 1126: train loss: 0.1286, test loss 0.1332\n",
      "Epoch 1127: train loss: 0.1285, test loss 0.1332\n",
      "Epoch 1128: train loss: 0.1285, test loss 0.1332\n",
      "Epoch 1129: train loss: 0.1285, test loss 0.1332\n",
      "Epoch 1130: train loss: 0.1285, test loss 0.1331\n",
      "Epoch 1131: train loss: 0.1285, test loss 0.1330\n",
      "Epoch 1132: train loss: 0.1285, test loss 0.1330\n",
      "Epoch 1133: train loss: 0.1285, test loss 0.1330\n",
      "Epoch 1134: train loss: 0.1284, test loss 0.1331\n",
      "Epoch 1135: train loss: 0.1284, test loss 0.1331\n",
      "Epoch 1136: train loss: 0.1284, test loss 0.1331\n",
      "Epoch 1137: train loss: 0.1284, test loss 0.1330\n",
      "Epoch 1138: train loss: 0.1284, test loss 0.1329\n",
      "Epoch 1139: train loss: 0.1284, test loss 0.1329\n",
      "Epoch 1140: train loss: 0.1283, test loss 0.1329\n",
      "Epoch 1141: train loss: 0.1283, test loss 0.1329\n",
      "Epoch 1142: train loss: 0.1283, test loss 0.1330\n",
      "Epoch 1143: train loss: 0.1283, test loss 0.1329\n",
      "Epoch 1144: train loss: 0.1283, test loss 0.1328\n",
      "Epoch 1145: train loss: 0.1283, test loss 0.1327\n",
      "Epoch 1146: train loss: 0.1283, test loss 0.1327\n",
      "Epoch 1147: train loss: 0.1282, test loss 0.1328\n",
      "Epoch 1148: train loss: 0.1282, test loss 0.1328\n",
      "Epoch 1149: train loss: 0.1282, test loss 0.1328\n",
      "Epoch 1150: train loss: 0.1282, test loss 0.1328\n",
      "Epoch 1151: train loss: 0.1282, test loss 0.1327\n",
      "Epoch 1152: train loss: 0.1282, test loss 0.1327\n",
      "Epoch 1153: train loss: 0.1281, test loss 0.1326\n",
      "Epoch 1154: train loss: 0.1281, test loss 0.1326\n",
      "Epoch 1155: train loss: 0.1281, test loss 0.1327\n",
      "Epoch 1156: train loss: 0.1281, test loss 0.1327\n",
      "Epoch 1157: train loss: 0.1281, test loss 0.1326\n",
      "Epoch 1158: train loss: 0.1281, test loss 0.1326\n",
      "Epoch 1159: train loss: 0.1280, test loss 0.1325\n",
      "Epoch 1160: train loss: 0.1280, test loss 0.1325\n",
      "Epoch 1161: train loss: 0.1280, test loss 0.1324\n",
      "Epoch 1162: train loss: 0.1280, test loss 0.1325\n",
      "Epoch 1163: train loss: 0.1280, test loss 0.1326\n",
      "Epoch 1164: train loss: 0.1280, test loss 0.1326\n",
      "Epoch 1165: train loss: 0.1280, test loss 0.1325\n",
      "Epoch 1166: train loss: 0.1279, test loss 0.1324\n",
      "Epoch 1167: train loss: 0.1279, test loss 0.1324\n",
      "Epoch 1168: train loss: 0.1279, test loss 0.1324\n",
      "Epoch 1169: train loss: 0.1279, test loss 0.1324\n",
      "Epoch 1170: train loss: 0.1279, test loss 0.1324\n",
      "Epoch 1171: train loss: 0.1279, test loss 0.1324\n",
      "Epoch 1172: train loss: 0.1278, test loss 0.1324\n",
      "Epoch 1173: train loss: 0.1278, test loss 0.1324\n",
      "Epoch 1174: train loss: 0.1278, test loss 0.1324\n",
      "Epoch 1175: train loss: 0.1278, test loss 0.1323\n",
      "Epoch 1176: train loss: 0.1278, test loss 0.1323\n",
      "Epoch 1177: train loss: 0.1278, test loss 0.1323\n",
      "Epoch 1178: train loss: 0.1278, test loss 0.1323\n",
      "Epoch 1179: train loss: 0.1277, test loss 0.1323\n",
      "Epoch 1180: train loss: 0.1277, test loss 0.1322\n",
      "Epoch 1181: train loss: 0.1277, test loss 0.1322\n",
      "Epoch 1182: train loss: 0.1277, test loss 0.1322\n",
      "Epoch 1183: train loss: 0.1277, test loss 0.1322\n",
      "Epoch 1184: train loss: 0.1277, test loss 0.1322\n",
      "Epoch 1185: train loss: 0.1277, test loss 0.1321\n",
      "Epoch 1186: train loss: 0.1276, test loss 0.1320\n",
      "Epoch 1187: train loss: 0.1276, test loss 0.1320\n",
      "Epoch 1188: train loss: 0.1276, test loss 0.1321\n",
      "Epoch 1189: train loss: 0.1276, test loss 0.1321\n",
      "Epoch 1190: train loss: 0.1276, test loss 0.1320\n",
      "Epoch 1191: train loss: 0.1276, test loss 0.1319\n",
      "Epoch 1192: train loss: 0.1276, test loss 0.1319\n",
      "Epoch 1193: train loss: 0.1275, test loss 0.1318\n",
      "Epoch 1194: train loss: 0.1275, test loss 0.1319\n",
      "Epoch 1195: train loss: 0.1275, test loss 0.1319\n",
      "Epoch 1196: train loss: 0.1275, test loss 0.1318\n",
      "Epoch 1197: train loss: 0.1275, test loss 0.1318\n",
      "Epoch 1198: train loss: 0.1275, test loss 0.1318\n",
      "Epoch 1199: train loss: 0.1274, test loss 0.1317\n",
      "Epoch 1200: train loss: 0.1274, test loss 0.1317\n",
      "Epoch 1201: train loss: 0.1274, test loss 0.1316\n",
      "Epoch 1202: train loss: 0.1274, test loss 0.1316\n",
      "Epoch 1203: train loss: 0.1274, test loss 0.1316\n",
      "Epoch 1204: train loss: 0.1274, test loss 0.1316\n",
      "Epoch 1205: train loss: 0.1274, test loss 0.1316\n",
      "Epoch 1206: train loss: 0.1273, test loss 0.1316\n",
      "Epoch 1207: train loss: 0.1273, test loss 0.1315\n",
      "Epoch 1208: train loss: 0.1273, test loss 0.1314\n",
      "Epoch 1209: train loss: 0.1273, test loss 0.1313\n",
      "Epoch 1210: train loss: 0.1273, test loss 0.1314\n",
      "Epoch 1211: train loss: 0.1273, test loss 0.1314\n",
      "Epoch 1212: train loss: 0.1273, test loss 0.1313\n",
      "Epoch 1213: train loss: 0.1272, test loss 0.1312\n",
      "Epoch 1214: train loss: 0.1272, test loss 0.1312\n",
      "Epoch 1215: train loss: 0.1272, test loss 0.1312\n",
      "Epoch 1216: train loss: 0.1272, test loss 0.1312\n",
      "Epoch 1217: train loss: 0.1272, test loss 0.1312\n",
      "Epoch 1218: train loss: 0.1272, test loss 0.1311\n",
      "Epoch 1219: train loss: 0.1272, test loss 0.1311\n",
      "Epoch 1220: train loss: 0.1271, test loss 0.1310\n",
      "Epoch 1221: train loss: 0.1271, test loss 0.1310\n",
      "Epoch 1222: train loss: 0.1271, test loss 0.1310\n",
      "Epoch 1223: train loss: 0.1271, test loss 0.1310\n",
      "Epoch 1224: train loss: 0.1271, test loss 0.1310\n",
      "Epoch 1225: train loss: 0.1271, test loss 0.1310\n",
      "Epoch 1226: train loss: 0.1271, test loss 0.1310\n",
      "Epoch 1227: train loss: 0.1270, test loss 0.1309\n",
      "Epoch 1228: train loss: 0.1270, test loss 0.1309\n",
      "Epoch 1229: train loss: 0.1270, test loss 0.1309\n",
      "Epoch 1230: train loss: 0.1270, test loss 0.1308\n",
      "Epoch 1231: train loss: 0.1270, test loss 0.1308\n",
      "Epoch 1232: train loss: 0.1270, test loss 0.1308\n",
      "Epoch 1233: train loss: 0.1270, test loss 0.1307\n",
      "Epoch 1234: train loss: 0.1269, test loss 0.1306\n",
      "Epoch 1235: train loss: 0.1269, test loss 0.1307\n",
      "Epoch 1236: train loss: 0.1269, test loss 0.1308\n",
      "Epoch 1237: train loss: 0.1269, test loss 0.1308\n",
      "Epoch 1238: train loss: 0.1269, test loss 0.1307\n",
      "Epoch 1239: train loss: 0.1269, test loss 0.1305\n",
      "Epoch 1240: train loss: 0.1269, test loss 0.1305\n",
      "Epoch 1241: train loss: 0.1268, test loss 0.1305\n",
      "Epoch 1242: train loss: 0.1268, test loss 0.1306\n",
      "Epoch 1243: train loss: 0.1268, test loss 0.1305\n",
      "Epoch 1244: train loss: 0.1268, test loss 0.1304\n",
      "Epoch 1245: train loss: 0.1268, test loss 0.1303\n",
      "Epoch 1246: train loss: 0.1268, test loss 0.1304\n",
      "Epoch 1247: train loss: 0.1268, test loss 0.1304\n",
      "Epoch 1248: train loss: 0.1267, test loss 0.1304\n",
      "Epoch 1249: train loss: 0.1267, test loss 0.1303\n",
      "Epoch 1250: train loss: 0.1267, test loss 0.1301\n",
      "Epoch 1251: train loss: 0.1267, test loss 0.1300\n",
      "Epoch 1252: train loss: 0.1267, test loss 0.1300\n",
      "Epoch 1253: train loss: 0.1267, test loss 0.1301\n",
      "Epoch 1254: train loss: 0.1267, test loss 0.1301\n",
      "Epoch 1255: train loss: 0.1266, test loss 0.1300\n",
      "Epoch 1256: train loss: 0.1266, test loss 0.1298\n",
      "Epoch 1257: train loss: 0.1266, test loss 0.1298\n",
      "Epoch 1258: train loss: 0.1266, test loss 0.1298\n",
      "Epoch 1259: train loss: 0.1266, test loss 0.1298\n",
      "Epoch 1260: train loss: 0.1266, test loss 0.1298\n",
      "Epoch 1261: train loss: 0.1265, test loss 0.1297\n",
      "Epoch 1262: train loss: 0.1265, test loss 0.1296\n",
      "Epoch 1263: train loss: 0.1265, test loss 0.1295\n",
      "Epoch 1264: train loss: 0.1265, test loss 0.1295\n",
      "Epoch 1265: train loss: 0.1265, test loss 0.1294\n",
      "Epoch 1266: train loss: 0.1265, test loss 0.1293\n",
      "Epoch 1267: train loss: 0.1265, test loss 0.1292\n",
      "Epoch 1268: train loss: 0.1264, test loss 0.1292\n",
      "Epoch 1269: train loss: 0.1264, test loss 0.1292\n",
      "Epoch 1270: train loss: 0.1264, test loss 0.1291\n",
      "Epoch 1271: train loss: 0.1264, test loss 0.1290\n",
      "Epoch 1272: train loss: 0.1264, test loss 0.1289\n",
      "Epoch 1273: train loss: 0.1264, test loss 0.1288\n",
      "Epoch 1274: train loss: 0.1263, test loss 0.1288\n",
      "Epoch 1275: train loss: 0.1263, test loss 0.1288\n",
      "Epoch 1276: train loss: 0.1263, test loss 0.1288\n",
      "Epoch 1277: train loss: 0.1263, test loss 0.1287\n",
      "Epoch 1278: train loss: 0.1263, test loss 0.1287\n",
      "Epoch 1279: train loss: 0.1263, test loss 0.1286\n",
      "Epoch 1280: train loss: 0.1263, test loss 0.1286\n",
      "Epoch 1281: train loss: 0.1262, test loss 0.1285\n",
      "Epoch 1282: train loss: 0.1262, test loss 0.1284\n",
      "Epoch 1283: train loss: 0.1262, test loss 0.1284\n",
      "Epoch 1284: train loss: 0.1262, test loss 0.1284\n",
      "Epoch 1285: train loss: 0.1262, test loss 0.1284\n",
      "Epoch 1286: train loss: 0.1262, test loss 0.1282\n",
      "Epoch 1287: train loss: 0.1262, test loss 0.1281\n",
      "Epoch 1288: train loss: 0.1261, test loss 0.1281\n",
      "Epoch 1289: train loss: 0.1261, test loss 0.1282\n",
      "Epoch 1290: train loss: 0.1261, test loss 0.1283\n",
      "Epoch 1291: train loss: 0.1261, test loss 0.1283\n",
      "Epoch 1292: train loss: 0.1261, test loss 0.1281\n",
      "Epoch 1293: train loss: 0.1261, test loss 0.1279\n",
      "Epoch 1294: train loss: 0.1261, test loss 0.1278\n",
      "Epoch 1295: train loss: 0.1260, test loss 0.1279\n",
      "Epoch 1296: train loss: 0.1260, test loss 0.1280\n",
      "Epoch 1297: train loss: 0.1260, test loss 0.1281\n",
      "Epoch 1298: train loss: 0.1260, test loss 0.1280\n",
      "Epoch 1299: train loss: 0.1260, test loss 0.1279\n",
      "Epoch 1300: train loss: 0.1260, test loss 0.1278\n",
      "Epoch 1301: train loss: 0.1260, test loss 0.1279\n",
      "Epoch 1302: train loss: 0.1259, test loss 0.1279\n",
      "Epoch 1303: train loss: 0.1259, test loss 0.1279\n",
      "Epoch 1304: train loss: 0.1259, test loss 0.1278\n",
      "Epoch 1305: train loss: 0.1259, test loss 0.1277\n",
      "Epoch 1306: train loss: 0.1259, test loss 0.1278\n",
      "Epoch 1307: train loss: 0.1259, test loss 0.1279\n",
      "Epoch 1308: train loss: 0.1259, test loss 0.1280\n",
      "Epoch 1309: train loss: 0.1259, test loss 0.1279\n",
      "Epoch 1310: train loss: 0.1258, test loss 0.1278\n",
      "Epoch 1311: train loss: 0.1258, test loss 0.1276\n",
      "Epoch 1312: train loss: 0.1258, test loss 0.1276\n",
      "Epoch 1313: train loss: 0.1258, test loss 0.1277\n",
      "Epoch 1314: train loss: 0.1258, test loss 0.1279\n",
      "Epoch 1315: train loss: 0.1258, test loss 0.1279\n",
      "Epoch 1316: train loss: 0.1258, test loss 0.1278\n",
      "Epoch 1317: train loss: 0.1257, test loss 0.1276\n",
      "Epoch 1318: train loss: 0.1257, test loss 0.1275\n",
      "Epoch 1319: train loss: 0.1257, test loss 0.1276\n",
      "Epoch 1320: train loss: 0.1257, test loss 0.1277\n",
      "Epoch 1321: train loss: 0.1257, test loss 0.1278\n",
      "Epoch 1322: train loss: 0.1257, test loss 0.1277\n",
      "Epoch 1323: train loss: 0.1257, test loss 0.1275\n",
      "Epoch 1324: train loss: 0.1256, test loss 0.1274\n",
      "Epoch 1325: train loss: 0.1256, test loss 0.1275\n",
      "Epoch 1326: train loss: 0.1256, test loss 0.1276\n",
      "Epoch 1327: train loss: 0.1256, test loss 0.1276\n",
      "Epoch 1328: train loss: 0.1256, test loss 0.1275\n",
      "Epoch 1329: train loss: 0.1256, test loss 0.1274\n",
      "Epoch 1330: train loss: 0.1255, test loss 0.1274\n",
      "Epoch 1331: train loss: 0.1255, test loss 0.1274\n",
      "Epoch 1332: train loss: 0.1255, test loss 0.1274\n",
      "Epoch 1333: train loss: 0.1255, test loss 0.1273\n",
      "Epoch 1334: train loss: 0.1255, test loss 0.1272\n",
      "Epoch 1335: train loss: 0.1254, test loss 0.1271\n",
      "Epoch 1336: train loss: 0.1254, test loss 0.1272\n",
      "Epoch 1337: train loss: 0.1254, test loss 0.1273\n",
      "Epoch 1338: train loss: 0.1254, test loss 0.1274\n",
      "Epoch 1339: train loss: 0.1254, test loss 0.1273\n",
      "Epoch 1340: train loss: 0.1253, test loss 0.1271\n",
      "Epoch 1341: train loss: 0.1253, test loss 0.1270\n",
      "Epoch 1342: train loss: 0.1253, test loss 0.1269\n",
      "Epoch 1343: train loss: 0.1253, test loss 0.1270\n",
      "Epoch 1344: train loss: 0.1252, test loss 0.1270\n",
      "Epoch 1345: train loss: 0.1252, test loss 0.1271\n",
      "Epoch 1346: train loss: 0.1252, test loss 0.1271\n",
      "Epoch 1347: train loss: 0.1252, test loss 0.1270\n",
      "Epoch 1348: train loss: 0.1251, test loss 0.1269\n",
      "Epoch 1349: train loss: 0.1251, test loss 0.1269\n",
      "Epoch 1350: train loss: 0.1251, test loss 0.1269\n",
      "Epoch 1351: train loss: 0.1250, test loss 0.1270\n",
      "Epoch 1352: train loss: 0.1250, test loss 0.1270\n",
      "Epoch 1353: train loss: 0.1249, test loss 0.1269\n",
      "Epoch 1354: train loss: 0.1249, test loss 0.1268\n",
      "Epoch 1355: train loss: 0.1249, test loss 0.1267\n",
      "Epoch 1356: train loss: 0.1248, test loss 0.1268\n",
      "Epoch 1357: train loss: 0.1248, test loss 0.1268\n",
      "Epoch 1358: train loss: 0.1248, test loss 0.1269\n",
      "Epoch 1359: train loss: 0.1247, test loss 0.1268\n",
      "Epoch 1360: train loss: 0.1247, test loss 0.1267\n",
      "Epoch 1361: train loss: 0.1247, test loss 0.1266\n",
      "Epoch 1362: train loss: 0.1247, test loss 0.1266\n",
      "Epoch 1363: train loss: 0.1246, test loss 0.1267\n",
      "Epoch 1364: train loss: 0.1246, test loss 0.1267\n",
      "Epoch 1365: train loss: 0.1246, test loss 0.1266\n",
      "Epoch 1366: train loss: 0.1245, test loss 0.1266\n",
      "Epoch 1367: train loss: 0.1245, test loss 0.1266\n",
      "Epoch 1368: train loss: 0.1245, test loss 0.1266\n",
      "Epoch 1369: train loss: 0.1245, test loss 0.1267\n",
      "Epoch 1370: train loss: 0.1244, test loss 0.1266\n",
      "Epoch 1371: train loss: 0.1244, test loss 0.1266\n",
      "Epoch 1372: train loss: 0.1244, test loss 0.1265\n",
      "Epoch 1373: train loss: 0.1244, test loss 0.1265\n",
      "Epoch 1374: train loss: 0.1243, test loss 0.1265\n",
      "Epoch 1375: train loss: 0.1243, test loss 0.1265\n",
      "Epoch 1376: train loss: 0.1243, test loss 0.1265\n",
      "Epoch 1377: train loss: 0.1243, test loss 0.1264\n",
      "Epoch 1378: train loss: 0.1242, test loss 0.1263\n",
      "Epoch 1379: train loss: 0.1242, test loss 0.1264\n",
      "Epoch 1380: train loss: 0.1242, test loss 0.1264\n",
      "Epoch 1381: train loss: 0.1241, test loss 0.1263\n",
      "Epoch 1382: train loss: 0.1241, test loss 0.1263\n",
      "Epoch 1383: train loss: 0.1241, test loss 0.1262\n",
      "Epoch 1384: train loss: 0.1240, test loss 0.1261\n",
      "Epoch 1385: train loss: 0.1240, test loss 0.1261\n",
      "Epoch 1386: train loss: 0.1239, test loss 0.1261\n",
      "Epoch 1387: train loss: 0.1239, test loss 0.1261\n",
      "Epoch 1388: train loss: 0.1238, test loss 0.1261\n",
      "Epoch 1389: train loss: 0.1238, test loss 0.1260\n",
      "Epoch 1390: train loss: 0.1237, test loss 0.1259\n",
      "Epoch 1391: train loss: 0.1236, test loss 0.1259\n",
      "Epoch 1392: train loss: 0.1236, test loss 0.1259\n",
      "Epoch 1393: train loss: 0.1235, test loss 0.1259\n",
      "Epoch 1394: train loss: 0.1234, test loss 0.1259\n",
      "Epoch 1395: train loss: 0.1233, test loss 0.1259\n",
      "Epoch 1396: train loss: 0.1232, test loss 0.1259\n",
      "Epoch 1397: train loss: 0.1231, test loss 0.1259\n",
      "Epoch 1398: train loss: 0.1230, test loss 0.1260\n",
      "Epoch 1399: train loss: 0.1228, test loss 0.1262\n",
      "Epoch 1400: train loss: 0.1227, test loss 0.1263\n",
      "Epoch 1401: train loss: 0.1226, test loss 0.1263\n",
      "Epoch 1402: train loss: 0.1225, test loss 0.1261\n",
      "Epoch 1403: train loss: 0.1225, test loss 0.1261\n",
      "Epoch 1404: train loss: 0.1224, test loss 0.1260\n",
      "Epoch 1405: train loss: 0.1223, test loss 0.1259\n",
      "Epoch 1406: train loss: 0.1222, test loss 0.1257\n",
      "Epoch 1407: train loss: 0.1222, test loss 0.1254\n",
      "Epoch 1408: train loss: 0.1221, test loss 0.1251\n",
      "Epoch 1409: train loss: 0.1221, test loss 0.1249\n",
      "Epoch 1410: train loss: 0.1221, test loss 0.1248\n",
      "Epoch 1411: train loss: 0.1220, test loss 0.1246\n",
      "Epoch 1412: train loss: 0.1220, test loss 0.1245\n",
      "Epoch 1413: train loss: 0.1219, test loss 0.1243\n",
      "Epoch 1414: train loss: 0.1219, test loss 0.1241\n",
      "Epoch 1415: train loss: 0.1219, test loss 0.1239\n",
      "Epoch 1416: train loss: 0.1218, test loss 0.1237\n",
      "Epoch 1417: train loss: 0.1218, test loss 0.1236\n",
      "Epoch 1418: train loss: 0.1218, test loss 0.1235\n",
      "Epoch 1419: train loss: 0.1217, test loss 0.1233\n",
      "Epoch 1420: train loss: 0.1217, test loss 0.1231\n",
      "Epoch 1421: train loss: 0.1217, test loss 0.1230\n",
      "Epoch 1422: train loss: 0.1216, test loss 0.1230\n",
      "Epoch 1423: train loss: 0.1216, test loss 0.1230\n",
      "Epoch 1424: train loss: 0.1215, test loss 0.1230\n",
      "Epoch 1425: train loss: 0.1215, test loss 0.1229\n",
      "Epoch 1426: train loss: 0.1215, test loss 0.1229\n",
      "Epoch 1427: train loss: 0.1214, test loss 0.1228\n",
      "Epoch 1428: train loss: 0.1214, test loss 0.1228\n",
      "Epoch 1429: train loss: 0.1214, test loss 0.1229\n",
      "Epoch 1430: train loss: 0.1213, test loss 0.1229\n",
      "Epoch 1431: train loss: 0.1213, test loss 0.1230\n",
      "Epoch 1432: train loss: 0.1213, test loss 0.1229\n",
      "Epoch 1433: train loss: 0.1212, test loss 0.1229\n",
      "Epoch 1434: train loss: 0.1212, test loss 0.1229\n",
      "Epoch 1435: train loss: 0.1212, test loss 0.1229\n",
      "Epoch 1436: train loss: 0.1211, test loss 0.1229\n",
      "Epoch 1437: train loss: 0.1211, test loss 0.1229\n",
      "Epoch 1438: train loss: 0.1211, test loss 0.1229\n",
      "Epoch 1439: train loss: 0.1211, test loss 0.1229\n",
      "Epoch 1440: train loss: 0.1210, test loss 0.1229\n",
      "Epoch 1441: train loss: 0.1210, test loss 0.1228\n",
      "Epoch 1442: train loss: 0.1210, test loss 0.1227\n",
      "Epoch 1443: train loss: 0.1210, test loss 0.1226\n",
      "Epoch 1444: train loss: 0.1209, test loss 0.1226\n",
      "Epoch 1445: train loss: 0.1209, test loss 0.1226\n",
      "Epoch 1446: train loss: 0.1209, test loss 0.1226\n",
      "Epoch 1447: train loss: 0.1208, test loss 0.1225\n",
      "Epoch 1448: train loss: 0.1208, test loss 0.1225\n",
      "Epoch 1449: train loss: 0.1208, test loss 0.1224\n",
      "Epoch 1450: train loss: 0.1208, test loss 0.1224\n",
      "Epoch 1451: train loss: 0.1207, test loss 0.1224\n",
      "Epoch 1452: train loss: 0.1207, test loss 0.1224\n",
      "Epoch 1453: train loss: 0.1207, test loss 0.1224\n",
      "Epoch 1454: train loss: 0.1207, test loss 0.1223\n",
      "Epoch 1455: train loss: 0.1206, test loss 0.1222\n",
      "Epoch 1456: train loss: 0.1206, test loss 0.1222\n",
      "Epoch 1457: train loss: 0.1206, test loss 0.1222\n",
      "Epoch 1458: train loss: 0.1206, test loss 0.1223\n",
      "Epoch 1459: train loss: 0.1205, test loss 0.1224\n",
      "Epoch 1460: train loss: 0.1205, test loss 0.1224\n",
      "Epoch 1461: train loss: 0.1205, test loss 0.1223\n",
      "Epoch 1462: train loss: 0.1204, test loss 0.1222\n",
      "Epoch 1463: train loss: 0.1204, test loss 0.1222\n",
      "Epoch 1464: train loss: 0.1204, test loss 0.1222\n",
      "Epoch 1465: train loss: 0.1204, test loss 0.1221\n",
      "Epoch 1466: train loss: 0.1203, test loss 0.1222\n",
      "Epoch 1467: train loss: 0.1203, test loss 0.1223\n",
      "Epoch 1468: train loss: 0.1203, test loss 0.1224\n",
      "Epoch 1469: train loss: 0.1203, test loss 0.1224\n",
      "Epoch 1470: train loss: 0.1202, test loss 0.1223\n",
      "Epoch 1471: train loss: 0.1202, test loss 0.1222\n",
      "Epoch 1472: train loss: 0.1202, test loss 0.1221\n",
      "Epoch 1473: train loss: 0.1202, test loss 0.1222\n",
      "Epoch 1474: train loss: 0.1201, test loss 0.1223\n",
      "Epoch 1475: train loss: 0.1201, test loss 0.1224\n",
      "Epoch 1476: train loss: 0.1201, test loss 0.1224\n",
      "Epoch 1477: train loss: 0.1201, test loss 0.1224\n",
      "Epoch 1478: train loss: 0.1201, test loss 0.1224\n",
      "Epoch 1479: train loss: 0.1200, test loss 0.1224\n",
      "Epoch 1480: train loss: 0.1200, test loss 0.1224\n",
      "Epoch 1481: train loss: 0.1200, test loss 0.1225\n",
      "Epoch 1482: train loss: 0.1200, test loss 0.1225\n",
      "Epoch 1483: train loss: 0.1199, test loss 0.1226\n",
      "Epoch 1484: train loss: 0.1199, test loss 0.1226\n",
      "Epoch 1485: train loss: 0.1199, test loss 0.1226\n",
      "Epoch 1486: train loss: 0.1199, test loss 0.1226\n",
      "Epoch 1487: train loss: 0.1198, test loss 0.1227\n",
      "Epoch 1488: train loss: 0.1198, test loss 0.1227\n",
      "Epoch 1489: train loss: 0.1198, test loss 0.1227\n",
      "Epoch 1490: train loss: 0.1198, test loss 0.1226\n",
      "Epoch 1491: train loss: 0.1198, test loss 0.1227\n",
      "Epoch 1492: train loss: 0.1197, test loss 0.1227\n",
      "Epoch 1493: train loss: 0.1197, test loss 0.1228\n",
      "Epoch 1494: train loss: 0.1197, test loss 0.1228\n",
      "Epoch 1495: train loss: 0.1197, test loss 0.1228\n",
      "Epoch 1496: train loss: 0.1196, test loss 0.1227\n",
      "Epoch 1497: train loss: 0.1196, test loss 0.1227\n",
      "Epoch 1498: train loss: 0.1196, test loss 0.1229\n",
      "Epoch 1499: train loss: 0.1196, test loss 0.1230\n",
      "Epoch 1500: train loss: 0.1196, test loss 0.1229\n",
      "Epoch 1501: train loss: 0.1195, test loss 0.1228\n",
      "Epoch 1502: train loss: 0.1195, test loss 0.1228\n",
      "Epoch 1503: train loss: 0.1195, test loss 0.1229\n",
      "Epoch 1504: train loss: 0.1195, test loss 0.1231\n",
      "Epoch 1505: train loss: 0.1194, test loss 0.1231\n",
      "Epoch 1506: train loss: 0.1194, test loss 0.1231\n",
      "Epoch 1507: train loss: 0.1194, test loss 0.1230\n",
      "Epoch 1508: train loss: 0.1194, test loss 0.1230\n",
      "Epoch 1509: train loss: 0.1194, test loss 0.1231\n",
      "Epoch 1510: train loss: 0.1193, test loss 0.1232\n",
      "Epoch 1511: train loss: 0.1193, test loss 0.1232\n",
      "Epoch 1512: train loss: 0.1193, test loss 0.1232\n",
      "Epoch 1513: train loss: 0.1193, test loss 0.1232\n",
      "Epoch 1514: train loss: 0.1193, test loss 0.1232\n",
      "Epoch 1515: train loss: 0.1192, test loss 0.1233\n",
      "Epoch 1516: train loss: 0.1192, test loss 0.1234\n",
      "Epoch 1517: train loss: 0.1192, test loss 0.1234\n",
      "Epoch 1518: train loss: 0.1192, test loss 0.1233\n",
      "Epoch 1519: train loss: 0.1192, test loss 0.1232\n",
      "Epoch 1520: train loss: 0.1191, test loss 0.1234\n",
      "Epoch 1521: train loss: 0.1191, test loss 0.1235\n",
      "Epoch 1522: train loss: 0.1191, test loss 0.1235\n",
      "Epoch 1523: train loss: 0.1191, test loss 0.1234\n",
      "Epoch 1524: train loss: 0.1191, test loss 0.1235\n",
      "Epoch 1525: train loss: 0.1190, test loss 0.1236\n",
      "Epoch 1526: train loss: 0.1190, test loss 0.1236\n",
      "Epoch 1527: train loss: 0.1190, test loss 0.1236\n",
      "Epoch 1528: train loss: 0.1190, test loss 0.1236\n",
      "Epoch 1529: train loss: 0.1190, test loss 0.1236\n",
      "Epoch 1530: train loss: 0.1189, test loss 0.1235\n",
      "Epoch 1531: train loss: 0.1189, test loss 0.1234\n",
      "Epoch 1532: train loss: 0.1189, test loss 0.1236\n",
      "Epoch 1533: train loss: 0.1189, test loss 0.1238\n",
      "Epoch 1534: train loss: 0.1189, test loss 0.1239\n",
      "Epoch 1535: train loss: 0.1188, test loss 0.1237\n",
      "Epoch 1536: train loss: 0.1188, test loss 0.1236\n",
      "Epoch 1537: train loss: 0.1188, test loss 0.1236\n",
      "Epoch 1538: train loss: 0.1188, test loss 0.1238\n",
      "Epoch 1539: train loss: 0.1188, test loss 0.1240\n",
      "Epoch 1540: train loss: 0.1187, test loss 0.1239\n",
      "Epoch 1541: train loss: 0.1187, test loss 0.1237\n",
      "Epoch 1542: train loss: 0.1187, test loss 0.1237\n",
      "Epoch 1543: train loss: 0.1187, test loss 0.1239\n",
      "Epoch 1544: train loss: 0.1187, test loss 0.1241\n",
      "Epoch 1545: train loss: 0.1187, test loss 0.1241\n",
      "Epoch 1546: train loss: 0.1186, test loss 0.1239\n",
      "Epoch 1547: train loss: 0.1186, test loss 0.1238\n",
      "Epoch 1548: train loss: 0.1186, test loss 0.1238\n",
      "Epoch 1549: train loss: 0.1186, test loss 0.1239\n",
      "Epoch 1550: train loss: 0.1186, test loss 0.1240\n",
      "Epoch 1551: train loss: 0.1185, test loss 0.1241\n",
      "Epoch 1552: train loss: 0.1185, test loss 0.1241\n",
      "Epoch 1553: train loss: 0.1185, test loss 0.1242\n",
      "Epoch 1554: train loss: 0.1185, test loss 0.1242\n",
      "Epoch 1555: train loss: 0.1185, test loss 0.1240\n",
      "Epoch 1556: train loss: 0.1185, test loss 0.1240\n",
      "Epoch 1557: train loss: 0.1184, test loss 0.1242\n",
      "Epoch 1558: train loss: 0.1184, test loss 0.1243\n",
      "Epoch 1559: train loss: 0.1184, test loss 0.1242\n",
      "Epoch 1560: train loss: 0.1184, test loss 0.1241\n",
      "Epoch 1561: train loss: 0.1184, test loss 0.1242\n",
      "Epoch 1562: train loss: 0.1184, test loss 0.1243\n",
      "Epoch 1563: train loss: 0.1183, test loss 0.1244\n",
      "Epoch 1564: train loss: 0.1183, test loss 0.1243\n",
      "Epoch 1565: train loss: 0.1183, test loss 0.1242\n",
      "Epoch 1566: train loss: 0.1183, test loss 0.1244\n",
      "Epoch 1567: train loss: 0.1183, test loss 0.1245\n",
      "Epoch 1568: train loss: 0.1183, test loss 0.1245\n",
      "Epoch 1569: train loss: 0.1182, test loss 0.1245\n",
      "Epoch 1570: train loss: 0.1182, test loss 0.1245\n",
      "Epoch 1571: train loss: 0.1182, test loss 0.1246\n",
      "Epoch 1572: train loss: 0.1182, test loss 0.1246\n",
      "Epoch 1573: train loss: 0.1182, test loss 0.1246\n",
      "Epoch 1574: train loss: 0.1182, test loss 0.1247\n",
      "Epoch 1575: train loss: 0.1181, test loss 0.1249\n",
      "Epoch 1576: train loss: 0.1181, test loss 0.1249\n",
      "Epoch 1577: train loss: 0.1181, test loss 0.1248\n",
      "Epoch 1578: train loss: 0.1181, test loss 0.1247\n",
      "Epoch 1579: train loss: 0.1181, test loss 0.1248\n",
      "Epoch 1580: train loss: 0.1180, test loss 0.1249\n",
      "Epoch 1581: train loss: 0.1180, test loss 0.1250\n",
      "Epoch 1582: train loss: 0.1180, test loss 0.1251\n",
      "Epoch 1583: train loss: 0.1180, test loss 0.1251\n",
      "Epoch 1584: train loss: 0.1180, test loss 0.1251\n",
      "Epoch 1585: train loss: 0.1180, test loss 0.1252\n",
      "Epoch 1586: train loss: 0.1179, test loss 0.1252\n",
      "Epoch 1587: train loss: 0.1179, test loss 0.1253\n",
      "Epoch 1588: train loss: 0.1179, test loss 0.1254\n",
      "Epoch 1589: train loss: 0.1179, test loss 0.1254\n",
      "Epoch 1590: train loss: 0.1179, test loss 0.1254\n",
      "Epoch 1591: train loss: 0.1179, test loss 0.1254\n",
      "Epoch 1592: train loss: 0.1178, test loss 0.1256\n",
      "Epoch 1593: train loss: 0.1178, test loss 0.1257\n",
      "Epoch 1594: train loss: 0.1178, test loss 0.1256\n",
      "Epoch 1595: train loss: 0.1178, test loss 0.1256\n",
      "Epoch 1596: train loss: 0.1178, test loss 0.1257\n",
      "Epoch 1597: train loss: 0.1177, test loss 0.1259\n",
      "Epoch 1598: train loss: 0.1177, test loss 0.1259\n",
      "Epoch 1599: train loss: 0.1177, test loss 0.1259\n",
      "Epoch 1600: train loss: 0.1177, test loss 0.1258\n",
      "Epoch 1601: train loss: 0.1177, test loss 0.1259\n",
      "Epoch 1602: train loss: 0.1176, test loss 0.1262\n",
      "Epoch 1603: train loss: 0.1176, test loss 0.1263\n",
      "Epoch 1604: train loss: 0.1176, test loss 0.1261\n",
      "Epoch 1605: train loss: 0.1176, test loss 0.1260\n",
      "Epoch 1606: train loss: 0.1176, test loss 0.1262\n",
      "Epoch 1607: train loss: 0.1176, test loss 0.1265\n",
      "Epoch 1608: train loss: 0.1175, test loss 0.1267\n",
      "Epoch 1609: train loss: 0.1175, test loss 0.1267\n",
      "Epoch 1610: train loss: 0.1175, test loss 0.1265\n",
      "Epoch 1611: train loss: 0.1175, test loss 0.1266\n",
      "Epoch 1612: train loss: 0.1175, test loss 0.1269\n",
      "Epoch 1613: train loss: 0.1175, test loss 0.1271\n",
      "Epoch 1614: train loss: 0.1174, test loss 0.1271\n",
      "Epoch 1615: train loss: 0.1174, test loss 0.1271\n",
      "Epoch 1616: train loss: 0.1174, test loss 0.1271\n",
      "Epoch 1617: train loss: 0.1174, test loss 0.1271\n",
      "Epoch 1618: train loss: 0.1174, test loss 0.1272\n",
      "Epoch 1619: train loss: 0.1173, test loss 0.1273\n",
      "Epoch 1620: train loss: 0.1173, test loss 0.1273\n",
      "Epoch 1621: train loss: 0.1173, test loss 0.1274\n",
      "Epoch 1622: train loss: 0.1173, test loss 0.1274\n",
      "Epoch 1623: train loss: 0.1173, test loss 0.1274\n",
      "Epoch 1624: train loss: 0.1173, test loss 0.1273\n",
      "Epoch 1625: train loss: 0.1172, test loss 0.1273\n",
      "Epoch 1626: train loss: 0.1172, test loss 0.1276\n",
      "Epoch 1627: train loss: 0.1172, test loss 0.1277\n",
      "Epoch 1628: train loss: 0.1172, test loss 0.1278\n",
      "Epoch 1629: train loss: 0.1172, test loss 0.1279\n",
      "Epoch 1630: train loss: 0.1172, test loss 0.1278\n",
      "Epoch 1631: train loss: 0.1171, test loss 0.1278\n",
      "Epoch 1632: train loss: 0.1171, test loss 0.1279\n",
      "Epoch 1633: train loss: 0.1171, test loss 0.1281\n",
      "Epoch 1634: train loss: 0.1171, test loss 0.1282\n",
      "Epoch 1635: train loss: 0.1171, test loss 0.1283\n",
      "Epoch 1636: train loss: 0.1171, test loss 0.1281\n",
      "Epoch 1637: train loss: 0.1170, test loss 0.1281\n",
      "Epoch 1638: train loss: 0.1170, test loss 0.1283\n",
      "Epoch 1639: train loss: 0.1170, test loss 0.1286\n",
      "Epoch 1640: train loss: 0.1170, test loss 0.1286\n",
      "Epoch 1641: train loss: 0.1170, test loss 0.1284\n",
      "Epoch 1642: train loss: 0.1170, test loss 0.1283\n",
      "Epoch 1643: train loss: 0.1169, test loss 0.1285\n",
      "Epoch 1644: train loss: 0.1169, test loss 0.1288\n",
      "Epoch 1645: train loss: 0.1169, test loss 0.1289\n",
      "Epoch 1646: train loss: 0.1169, test loss 0.1286\n",
      "Epoch 1647: train loss: 0.1169, test loss 0.1286\n",
      "Epoch 1648: train loss: 0.1169, test loss 0.1288\n",
      "Epoch 1649: train loss: 0.1168, test loss 0.1293\n",
      "Epoch 1650: train loss: 0.1168, test loss 0.1293\n",
      "Epoch 1651: train loss: 0.1168, test loss 0.1290\n",
      "Epoch 1652: train loss: 0.1168, test loss 0.1289\n",
      "Epoch 1653: train loss: 0.1168, test loss 0.1292\n",
      "Epoch 1654: train loss: 0.1168, test loss 0.1295\n",
      "Epoch 1655: train loss: 0.1167, test loss 0.1294\n",
      "Epoch 1656: train loss: 0.1167, test loss 0.1292\n",
      "Epoch 1657: train loss: 0.1167, test loss 0.1293\n",
      "Epoch 1658: train loss: 0.1167, test loss 0.1297\n",
      "Epoch 1659: train loss: 0.1167, test loss 0.1297\n",
      "Epoch 1660: train loss: 0.1167, test loss 0.1294\n",
      "Epoch 1661: train loss: 0.1167, test loss 0.1294\n",
      "Epoch 1662: train loss: 0.1166, test loss 0.1297\n",
      "Epoch 1663: train loss: 0.1166, test loss 0.1299\n",
      "Epoch 1664: train loss: 0.1166, test loss 0.1299\n",
      "Epoch 1665: train loss: 0.1166, test loss 0.1298\n",
      "Epoch 1666: train loss: 0.1166, test loss 0.1298\n",
      "Epoch 1667: train loss: 0.1166, test loss 0.1298\n",
      "Epoch 1668: train loss: 0.1165, test loss 0.1300\n",
      "Epoch 1669: train loss: 0.1165, test loss 0.1301\n",
      "Epoch 1670: train loss: 0.1165, test loss 0.1302\n",
      "Epoch 1671: train loss: 0.1165, test loss 0.1300\n",
      "Epoch 1672: train loss: 0.1165, test loss 0.1300\n",
      "Epoch 1673: train loss: 0.1165, test loss 0.1302\n",
      "Epoch 1674: train loss: 0.1165, test loss 0.1302\n",
      "Epoch 1675: train loss: 0.1164, test loss 0.1301\n",
      "Epoch 1676: train loss: 0.1164, test loss 0.1301\n",
      "Epoch 1677: train loss: 0.1164, test loss 0.1303\n",
      "Epoch 1678: train loss: 0.1164, test loss 0.1304\n",
      "Epoch 1679: train loss: 0.1164, test loss 0.1305\n",
      "Epoch 1680: train loss: 0.1164, test loss 0.1303\n",
      "Epoch 1681: train loss: 0.1163, test loss 0.1302\n",
      "Epoch 1682: train loss: 0.1163, test loss 0.1302\n",
      "Epoch 1683: train loss: 0.1163, test loss 0.1303\n",
      "Epoch 1684: train loss: 0.1163, test loss 0.1305\n",
      "Epoch 1685: train loss: 0.1163, test loss 0.1306\n",
      "Epoch 1686: train loss: 0.1163, test loss 0.1304\n",
      "Epoch 1687: train loss: 0.1162, test loss 0.1303\n",
      "Epoch 1688: train loss: 0.1162, test loss 0.1303\n",
      "Epoch 1689: train loss: 0.1162, test loss 0.1305\n",
      "Epoch 1690: train loss: 0.1162, test loss 0.1308\n",
      "Epoch 1691: train loss: 0.1162, test loss 0.1308\n",
      "Epoch 1692: train loss: 0.1162, test loss 0.1307\n",
      "Epoch 1693: train loss: 0.1161, test loss 0.1307\n",
      "Epoch 1694: train loss: 0.1161, test loss 0.1308\n",
      "Epoch 1695: train loss: 0.1161, test loss 0.1308\n",
      "Epoch 1696: train loss: 0.1161, test loss 0.1310\n",
      "Epoch 1697: train loss: 0.1161, test loss 0.1311\n",
      "Epoch 1698: train loss: 0.1160, test loss 0.1311\n",
      "Epoch 1699: train loss: 0.1160, test loss 0.1312\n",
      "Epoch 1700: train loss: 0.1160, test loss 0.1313\n",
      "Epoch 1701: train loss: 0.1160, test loss 0.1312\n",
      "Epoch 1702: train loss: 0.1160, test loss 0.1313\n",
      "Epoch 1703: train loss: 0.1160, test loss 0.1315\n",
      "Epoch 1704: train loss: 0.1159, test loss 0.1316\n",
      "Epoch 1705: train loss: 0.1159, test loss 0.1314\n",
      "Epoch 1706: train loss: 0.1159, test loss 0.1314\n",
      "Epoch 1707: train loss: 0.1159, test loss 0.1316\n",
      "Epoch 1708: train loss: 0.1159, test loss 0.1318\n",
      "Epoch 1709: train loss: 0.1159, test loss 0.1316\n",
      "Epoch 1710: train loss: 0.1158, test loss 0.1315\n",
      "Epoch 1711: train loss: 0.1158, test loss 0.1314\n",
      "Epoch 1712: train loss: 0.1158, test loss 0.1315\n",
      "Epoch 1713: train loss: 0.1158, test loss 0.1315\n",
      "Epoch 1714: train loss: 0.1158, test loss 0.1316\n",
      "Epoch 1715: train loss: 0.1158, test loss 0.1315\n",
      "Epoch 1716: train loss: 0.1157, test loss 0.1315\n",
      "Epoch 1717: train loss: 0.1157, test loss 0.1315\n",
      "Epoch 1718: train loss: 0.1157, test loss 0.1316\n",
      "Epoch 1719: train loss: 0.1157, test loss 0.1314\n",
      "Epoch 1720: train loss: 0.1157, test loss 0.1313\n",
      "Epoch 1721: train loss: 0.1157, test loss 0.1314\n",
      "Epoch 1722: train loss: 0.1156, test loss 0.1315\n",
      "Epoch 1723: train loss: 0.1156, test loss 0.1317\n",
      "Epoch 1724: train loss: 0.1156, test loss 0.1315\n",
      "Epoch 1725: train loss: 0.1156, test loss 0.1314\n",
      "Epoch 1726: train loss: 0.1156, test loss 0.1315\n",
      "Epoch 1727: train loss: 0.1156, test loss 0.1316\n",
      "Epoch 1728: train loss: 0.1155, test loss 0.1314\n",
      "Epoch 1729: train loss: 0.1155, test loss 0.1311\n",
      "Epoch 1730: train loss: 0.1155, test loss 0.1314\n",
      "Epoch 1731: train loss: 0.1155, test loss 0.1318\n",
      "Epoch 1732: train loss: 0.1155, test loss 0.1317\n",
      "Epoch 1733: train loss: 0.1155, test loss 0.1311\n",
      "Epoch 1734: train loss: 0.1154, test loss 0.1311\n",
      "Epoch 1735: train loss: 0.1154, test loss 0.1315\n",
      "Epoch 1736: train loss: 0.1154, test loss 0.1316\n",
      "Epoch 1737: train loss: 0.1154, test loss 0.1313\n",
      "Epoch 1738: train loss: 0.1154, test loss 0.1313\n",
      "Epoch 1739: train loss: 0.1154, test loss 0.1314\n",
      "Epoch 1740: train loss: 0.1153, test loss 0.1314\n",
      "Epoch 1741: train loss: 0.1153, test loss 0.1314\n",
      "Epoch 1742: train loss: 0.1153, test loss 0.1313\n",
      "Epoch 1743: train loss: 0.1153, test loss 0.1311\n",
      "Epoch 1744: train loss: 0.1153, test loss 0.1312\n",
      "Epoch 1745: train loss: 0.1153, test loss 0.1314\n",
      "Epoch 1746: train loss: 0.1152, test loss 0.1312\n",
      "Epoch 1747: train loss: 0.1152, test loss 0.1310\n",
      "Epoch 1748: train loss: 0.1152, test loss 0.1309\n",
      "Epoch 1749: train loss: 0.1152, test loss 0.1310\n",
      "Epoch 1750: train loss: 0.1152, test loss 0.1310\n",
      "Epoch 1751: train loss: 0.1152, test loss 0.1309\n",
      "Epoch 1752: train loss: 0.1151, test loss 0.1309\n",
      "Epoch 1753: train loss: 0.1151, test loss 0.1307\n",
      "Epoch 1754: train loss: 0.1151, test loss 0.1307\n",
      "Epoch 1755: train loss: 0.1151, test loss 0.1311\n",
      "Epoch 1756: train loss: 0.1151, test loss 0.1309\n",
      "Epoch 1757: train loss: 0.1151, test loss 0.1304\n",
      "Epoch 1758: train loss: 0.1150, test loss 0.1307\n",
      "Epoch 1759: train loss: 0.1150, test loss 0.1309\n",
      "Epoch 1760: train loss: 0.1150, test loss 0.1306\n",
      "Epoch 1761: train loss: 0.1150, test loss 0.1303\n",
      "Epoch 1762: train loss: 0.1150, test loss 0.1308\n",
      "Epoch 1763: train loss: 0.1150, test loss 0.1308\n",
      "Epoch 1764: train loss: 0.1150, test loss 0.1303\n",
      "Epoch 1765: train loss: 0.1149, test loss 0.1304\n",
      "Epoch 1766: train loss: 0.1149, test loss 0.1307\n",
      "Epoch 1767: train loss: 0.1149, test loss 0.1305\n",
      "Epoch 1768: train loss: 0.1149, test loss 0.1305\n",
      "Epoch 1769: train loss: 0.1149, test loss 0.1306\n",
      "Epoch 1770: train loss: 0.1149, test loss 0.1305\n",
      "Epoch 1771: train loss: 0.1148, test loss 0.1304\n",
      "Epoch 1772: train loss: 0.1148, test loss 0.1303\n",
      "Epoch 1773: train loss: 0.1148, test loss 0.1306\n",
      "Epoch 1774: train loss: 0.1148, test loss 0.1306\n",
      "Epoch 1775: train loss: 0.1148, test loss 0.1303\n",
      "Epoch 1776: train loss: 0.1148, test loss 0.1303\n",
      "Epoch 1777: train loss: 0.1148, test loss 0.1306\n",
      "Epoch 1778: train loss: 0.1147, test loss 0.1306\n",
      "Epoch 1779: train loss: 0.1147, test loss 0.1306\n",
      "Epoch 1780: train loss: 0.1147, test loss 0.1302\n",
      "Epoch 1781: train loss: 0.1147, test loss 0.1302\n",
      "Epoch 1782: train loss: 0.1147, test loss 0.1306\n",
      "Epoch 1783: train loss: 0.1147, test loss 0.1307\n",
      "Epoch 1784: train loss: 0.1147, test loss 0.1304\n",
      "Epoch 1785: train loss: 0.1146, test loss 0.1303\n",
      "Epoch 1786: train loss: 0.1146, test loss 0.1306\n",
      "Epoch 1787: train loss: 0.1146, test loss 0.1304\n",
      "Epoch 1788: train loss: 0.1146, test loss 0.1303\n",
      "Epoch 1789: train loss: 0.1146, test loss 0.1305\n",
      "Epoch 1790: train loss: 0.1146, test loss 0.1307\n",
      "Epoch 1791: train loss: 0.1146, test loss 0.1304\n",
      "Epoch 1792: train loss: 0.1145, test loss 0.1303\n",
      "Epoch 1793: train loss: 0.1145, test loss 0.1304\n",
      "Epoch 1794: train loss: 0.1145, test loss 0.1303\n",
      "Epoch 1795: train loss: 0.1145, test loss 0.1302\n",
      "Epoch 1796: train loss: 0.1145, test loss 0.1305\n",
      "Epoch 1797: train loss: 0.1145, test loss 0.1304\n",
      "Epoch 1798: train loss: 0.1145, test loss 0.1302\n",
      "Epoch 1799: train loss: 0.1144, test loss 0.1301\n",
      "Epoch 1800: train loss: 0.1144, test loss 0.1305\n",
      "Epoch 1801: train loss: 0.1144, test loss 0.1304\n",
      "Epoch 1802: train loss: 0.1144, test loss 0.1301\n",
      "Epoch 1803: train loss: 0.1144, test loss 0.1300\n",
      "Epoch 1804: train loss: 0.1144, test loss 0.1303\n",
      "Epoch 1805: train loss: 0.1144, test loss 0.1303\n",
      "Epoch 1806: train loss: 0.1143, test loss 0.1302\n",
      "Epoch 1807: train loss: 0.1143, test loss 0.1301\n",
      "Epoch 1808: train loss: 0.1143, test loss 0.1300\n",
      "Epoch 1809: train loss: 0.1143, test loss 0.1300\n",
      "Epoch 1810: train loss: 0.1143, test loss 0.1302\n",
      "Epoch 1811: train loss: 0.1143, test loss 0.1301\n",
      "Epoch 1812: train loss: 0.1143, test loss 0.1298\n",
      "Epoch 1813: train loss: 0.1143, test loss 0.1298\n",
      "Epoch 1814: train loss: 0.1142, test loss 0.1302\n",
      "Epoch 1815: train loss: 0.1142, test loss 0.1297\n",
      "Epoch 1816: train loss: 0.1142, test loss 0.1293\n",
      "Epoch 1817: train loss: 0.1142, test loss 0.1299\n",
      "Epoch 1818: train loss: 0.1142, test loss 0.1304\n",
      "Epoch 1819: train loss: 0.1142, test loss 0.1297\n",
      "Epoch 1820: train loss: 0.1142, test loss 0.1292\n",
      "Epoch 1821: train loss: 0.1141, test loss 0.1297\n",
      "Epoch 1822: train loss: 0.1141, test loss 0.1299\n",
      "Epoch 1823: train loss: 0.1141, test loss 0.1296\n",
      "Epoch 1824: train loss: 0.1141, test loss 0.1298\n",
      "Epoch 1825: train loss: 0.1141, test loss 0.1298\n",
      "Epoch 1826: train loss: 0.1141, test loss 0.1294\n",
      "Epoch 1827: train loss: 0.1141, test loss 0.1295\n",
      "Epoch 1828: train loss: 0.1141, test loss 0.1300\n",
      "Epoch 1829: train loss: 0.1140, test loss 0.1295\n",
      "Epoch 1830: train loss: 0.1140, test loss 0.1292\n",
      "Epoch 1831: train loss: 0.1140, test loss 0.1298\n",
      "Epoch 1832: train loss: 0.1140, test loss 0.1299\n",
      "Epoch 1833: train loss: 0.1140, test loss 0.1294\n",
      "Epoch 1834: train loss: 0.1140, test loss 0.1291\n",
      "Epoch 1835: train loss: 0.1140, test loss 0.1296\n",
      "Epoch 1836: train loss: 0.1140, test loss 0.1298\n",
      "Epoch 1837: train loss: 0.1139, test loss 0.1296\n",
      "Epoch 1838: train loss: 0.1139, test loss 0.1291\n",
      "Epoch 1839: train loss: 0.1139, test loss 0.1291\n",
      "Epoch 1840: train loss: 0.1139, test loss 0.1293\n",
      "Epoch 1841: train loss: 0.1139, test loss 0.1298\n",
      "Epoch 1842: train loss: 0.1139, test loss 0.1294\n",
      "Epoch 1843: train loss: 0.1139, test loss 0.1290\n",
      "Epoch 1844: train loss: 0.1138, test loss 0.1292\n",
      "Epoch 1845: train loss: 0.1138, test loss 0.1292\n",
      "Epoch 1846: train loss: 0.1138, test loss 0.1294\n",
      "Epoch 1847: train loss: 0.1138, test loss 0.1294\n",
      "Epoch 1848: train loss: 0.1138, test loss 0.1290\n",
      "Epoch 1849: train loss: 0.1138, test loss 0.1290\n",
      "Epoch 1850: train loss: 0.1138, test loss 0.1294\n",
      "Epoch 1851: train loss: 0.1138, test loss 0.1296\n",
      "Epoch 1852: train loss: 0.1137, test loss 0.1293\n",
      "Epoch 1853: train loss: 0.1137, test loss 0.1290\n",
      "Epoch 1854: train loss: 0.1137, test loss 0.1289\n",
      "Epoch 1855: train loss: 0.1137, test loss 0.1291\n",
      "Epoch 1856: train loss: 0.1137, test loss 0.1295\n",
      "Epoch 1857: train loss: 0.1137, test loss 0.1291\n",
      "Epoch 1858: train loss: 0.1137, test loss 0.1290\n",
      "Epoch 1859: train loss: 0.1137, test loss 0.1294\n",
      "Epoch 1860: train loss: 0.1137, test loss 0.1290\n",
      "Epoch 1861: train loss: 0.1136, test loss 0.1286\n",
      "Epoch 1862: train loss: 0.1136, test loss 0.1293\n",
      "Epoch 1863: train loss: 0.1136, test loss 0.1293\n",
      "Epoch 1864: train loss: 0.1136, test loss 0.1288\n",
      "Epoch 1865: train loss: 0.1136, test loss 0.1290\n",
      "Epoch 1866: train loss: 0.1136, test loss 0.1292\n",
      "Epoch 1867: train loss: 0.1136, test loss 0.1288\n",
      "Epoch 1868: train loss: 0.1136, test loss 0.1287\n",
      "Epoch 1869: train loss: 0.1135, test loss 0.1289\n",
      "Epoch 1870: train loss: 0.1135, test loss 0.1290\n",
      "Epoch 1871: train loss: 0.1135, test loss 0.1291\n",
      "Epoch 1872: train loss: 0.1135, test loss 0.1285\n",
      "Epoch 1873: train loss: 0.1135, test loss 0.1287\n",
      "Epoch 1874: train loss: 0.1135, test loss 0.1289\n",
      "Epoch 1875: train loss: 0.1135, test loss 0.1287\n",
      "Epoch 1876: train loss: 0.1135, test loss 0.1289\n",
      "Epoch 1877: train loss: 0.1135, test loss 0.1291\n",
      "Epoch 1878: train loss: 0.1134, test loss 0.1283\n",
      "Epoch 1879: train loss: 0.1134, test loss 0.1282\n",
      "Epoch 1880: train loss: 0.1134, test loss 0.1292\n",
      "Epoch 1881: train loss: 0.1134, test loss 0.1289\n",
      "Epoch 1882: train loss: 0.1134, test loss 0.1279\n",
      "Epoch 1883: train loss: 0.1134, test loss 0.1287\n",
      "Epoch 1884: train loss: 0.1134, test loss 0.1293\n",
      "Epoch 1885: train loss: 0.1134, test loss 0.1286\n",
      "Epoch 1886: train loss: 0.1134, test loss 0.1282\n",
      "Epoch 1887: train loss: 0.1133, test loss 0.1285\n",
      "Epoch 1888: train loss: 0.1133, test loss 0.1286\n",
      "Epoch 1889: train loss: 0.1133, test loss 0.1287\n",
      "Epoch 1890: train loss: 0.1133, test loss 0.1286\n",
      "Epoch 1891: train loss: 0.1133, test loss 0.1282\n",
      "Epoch 1892: train loss: 0.1133, test loss 0.1284\n",
      "Epoch 1893: train loss: 0.1133, test loss 0.1285\n",
      "Epoch 1894: train loss: 0.1133, test loss 0.1285\n",
      "Epoch 1895: train loss: 0.1133, test loss 0.1284\n",
      "Epoch 1896: train loss: 0.1132, test loss 0.1282\n",
      "Epoch 1897: train loss: 0.1132, test loss 0.1286\n",
      "Epoch 1898: train loss: 0.1132, test loss 0.1284\n",
      "Epoch 1899: train loss: 0.1132, test loss 0.1281\n",
      "Epoch 1900: train loss: 0.1132, test loss 0.1286\n",
      "Epoch 1901: train loss: 0.1132, test loss 0.1285\n",
      "Epoch 1902: train loss: 0.1132, test loss 0.1281\n",
      "Epoch 1903: train loss: 0.1132, test loss 0.1284\n",
      "Epoch 1904: train loss: 0.1132, test loss 0.1284\n",
      "Epoch 1905: train loss: 0.1132, test loss 0.1280\n",
      "Epoch 1906: train loss: 0.1131, test loss 0.1282\n",
      "Epoch 1907: train loss: 0.1131, test loss 0.1284\n",
      "Epoch 1908: train loss: 0.1131, test loss 0.1279\n",
      "Epoch 1909: train loss: 0.1131, test loss 0.1280\n",
      "Epoch 1910: train loss: 0.1131, test loss 0.1281\n",
      "Epoch 1911: train loss: 0.1131, test loss 0.1281\n",
      "Epoch 1912: train loss: 0.1131, test loss 0.1279\n",
      "Epoch 1913: train loss: 0.1131, test loss 0.1280\n",
      "Epoch 1914: train loss: 0.1131, test loss 0.1277\n",
      "Epoch 1915: train loss: 0.1131, test loss 0.1276\n",
      "Epoch 1916: train loss: 0.1130, test loss 0.1281\n",
      "Epoch 1917: train loss: 0.1130, test loss 0.1278\n",
      "Epoch 1918: train loss: 0.1130, test loss 0.1274\n",
      "Epoch 1919: train loss: 0.1130, test loss 0.1279\n",
      "Epoch 1920: train loss: 0.1130, test loss 0.1278\n",
      "Epoch 1921: train loss: 0.1130, test loss 0.1272\n",
      "Epoch 1922: train loss: 0.1130, test loss 0.1277\n",
      "Epoch 1923: train loss: 0.1130, test loss 0.1279\n",
      "Epoch 1924: train loss: 0.1130, test loss 0.1275\n",
      "Epoch 1925: train loss: 0.1129, test loss 0.1275\n",
      "Epoch 1926: train loss: 0.1129, test loss 0.1275\n",
      "Epoch 1927: train loss: 0.1129, test loss 0.1274\n",
      "Epoch 1928: train loss: 0.1129, test loss 0.1276\n",
      "Epoch 1929: train loss: 0.1129, test loss 0.1275\n",
      "Epoch 1930: train loss: 0.1129, test loss 0.1273\n",
      "Epoch 1931: train loss: 0.1129, test loss 0.1274\n",
      "Epoch 1932: train loss: 0.1129, test loss 0.1274\n",
      "Epoch 1933: train loss: 0.1129, test loss 0.1275\n",
      "Epoch 1934: train loss: 0.1129, test loss 0.1275\n",
      "Epoch 1935: train loss: 0.1128, test loss 0.1272\n",
      "Epoch 1936: train loss: 0.1128, test loss 0.1273\n",
      "Epoch 1937: train loss: 0.1128, test loss 0.1275\n",
      "Epoch 1938: train loss: 0.1128, test loss 0.1275\n",
      "Epoch 1939: train loss: 0.1128, test loss 0.1272\n",
      "Epoch 1940: train loss: 0.1128, test loss 0.1275\n",
      "Epoch 1941: train loss: 0.1128, test loss 0.1273\n",
      "Epoch 1942: train loss: 0.1128, test loss 0.1270\n",
      "Epoch 1943: train loss: 0.1128, test loss 0.1276\n",
      "Epoch 1944: train loss: 0.1128, test loss 0.1275\n",
      "Epoch 1945: train loss: 0.1127, test loss 0.1271\n",
      "Epoch 1946: train loss: 0.1127, test loss 0.1275\n",
      "Epoch 1947: train loss: 0.1127, test loss 0.1273\n",
      "Epoch 1948: train loss: 0.1127, test loss 0.1269\n",
      "Epoch 1949: train loss: 0.1127, test loss 0.1274\n",
      "Epoch 1950: train loss: 0.1127, test loss 0.1275\n",
      "Epoch 1951: train loss: 0.1127, test loss 0.1270\n",
      "Epoch 1952: train loss: 0.1127, test loss 0.1273\n",
      "Epoch 1953: train loss: 0.1127, test loss 0.1272\n",
      "Epoch 1954: train loss: 0.1127, test loss 0.1269\n",
      "Epoch 1955: train loss: 0.1126, test loss 0.1272\n",
      "Epoch 1956: train loss: 0.1126, test loss 0.1276\n",
      "Epoch 1957: train loss: 0.1126, test loss 0.1270\n",
      "Epoch 1958: train loss: 0.1126, test loss 0.1267\n",
      "Epoch 1959: train loss: 0.1126, test loss 0.1276\n",
      "Epoch 1960: train loss: 0.1126, test loss 0.1272\n",
      "Epoch 1961: train loss: 0.1126, test loss 0.1265\n",
      "Epoch 1962: train loss: 0.1126, test loss 0.1273\n",
      "Epoch 1963: train loss: 0.1126, test loss 0.1275\n",
      "Epoch 1964: train loss: 0.1126, test loss 0.1269\n",
      "Epoch 1965: train loss: 0.1125, test loss 0.1271\n",
      "Epoch 1966: train loss: 0.1125, test loss 0.1271\n",
      "Epoch 1967: train loss: 0.1125, test loss 0.1269\n",
      "Epoch 1968: train loss: 0.1125, test loss 0.1272\n",
      "Epoch 1969: train loss: 0.1125, test loss 0.1276\n",
      "Epoch 1970: train loss: 0.1125, test loss 0.1269\n",
      "Epoch 1971: train loss: 0.1125, test loss 0.1265\n",
      "Epoch 1972: train loss: 0.1125, test loss 0.1276\n",
      "Epoch 1973: train loss: 0.1125, test loss 0.1273\n",
      "Epoch 1974: train loss: 0.1125, test loss 0.1264\n",
      "Epoch 1975: train loss: 0.1125, test loss 0.1274\n",
      "Epoch 1976: train loss: 0.1124, test loss 0.1275\n",
      "Epoch 1977: train loss: 0.1124, test loss 0.1266\n",
      "Epoch 1978: train loss: 0.1124, test loss 0.1269\n",
      "Epoch 1979: train loss: 0.1124, test loss 0.1273\n",
      "Epoch 1980: train loss: 0.1124, test loss 0.1269\n",
      "Epoch 1981: train loss: 0.1124, test loss 0.1269\n",
      "Epoch 1982: train loss: 0.1124, test loss 0.1272\n",
      "Epoch 1983: train loss: 0.1124, test loss 0.1269\n",
      "Epoch 1984: train loss: 0.1124, test loss 0.1266\n",
      "Epoch 1985: train loss: 0.1124, test loss 0.1272\n",
      "Epoch 1986: train loss: 0.1123, test loss 0.1272\n",
      "Epoch 1987: train loss: 0.1123, test loss 0.1267\n",
      "Epoch 1988: train loss: 0.1123, test loss 0.1272\n",
      "Epoch 1989: train loss: 0.1123, test loss 0.1267\n",
      "Epoch 1990: train loss: 0.1123, test loss 0.1265\n",
      "Epoch 1991: train loss: 0.1123, test loss 0.1274\n",
      "Epoch 1992: train loss: 0.1123, test loss 0.1270\n",
      "Epoch 1993: train loss: 0.1123, test loss 0.1264\n",
      "Epoch 1994: train loss: 0.1123, test loss 0.1272\n",
      "Epoch 1995: train loss: 0.1123, test loss 0.1269\n",
      "Epoch 1996: train loss: 0.1123, test loss 0.1263\n",
      "Epoch 1997: train loss: 0.1122, test loss 0.1270\n",
      "Epoch 1998: train loss: 0.1122, test loss 0.1276\n",
      "Epoch 1999: train loss: 0.1122, test loss 0.1269\n",
      "Epoch 2000: train loss: 0.1122, test loss 0.1267\n",
      "Epoch 2001: train loss: 0.1122, test loss 0.1264\n",
      "Epoch 2002: train loss: 0.1122, test loss 0.1265\n",
      "Epoch 2003: train loss: 0.1122, test loss 0.1272\n",
      "Epoch 2004: train loss: 0.1122, test loss 0.1272\n",
      "Epoch 2005: train loss: 0.1122, test loss 0.1266\n",
      "Epoch 2006: train loss: 0.1122, test loss 0.1266\n",
      "Epoch 2007: train loss: 0.1122, test loss 0.1268\n",
      "Epoch 2008: train loss: 0.1122, test loss 0.1264\n",
      "Epoch 2009: train loss: 0.1121, test loss 0.1267\n",
      "Epoch 2010: train loss: 0.1121, test loss 0.1263\n",
      "Epoch 2011: train loss: 0.1121, test loss 0.1261\n",
      "Epoch 2012: train loss: 0.1121, test loss 0.1272\n",
      "Epoch 2013: train loss: 0.1121, test loss 0.1264\n",
      "Epoch 2014: train loss: 0.1121, test loss 0.1258\n",
      "Epoch 2015: train loss: 0.1121, test loss 0.1268\n",
      "Epoch 2016: train loss: 0.1121, test loss 0.1260\n",
      "Epoch 2017: train loss: 0.1121, test loss 0.1255\n",
      "Epoch 2018: train loss: 0.1121, test loss 0.1271\n",
      "Epoch 2019: train loss: 0.1121, test loss 0.1273\n",
      "Epoch 2020: train loss: 0.1121, test loss 0.1255\n",
      "Epoch 2021: train loss: 0.1120, test loss 0.1259\n",
      "Epoch 2022: train loss: 0.1120, test loss 0.1265\n",
      "Epoch 2023: train loss: 0.1120, test loss 0.1257\n",
      "Epoch 2024: train loss: 0.1120, test loss 0.1262\n",
      "Epoch 2025: train loss: 0.1120, test loss 0.1263\n",
      "Epoch 2026: train loss: 0.1120, test loss 0.1254\n",
      "Epoch 2027: train loss: 0.1120, test loss 0.1260\n",
      "Epoch 2028: train loss: 0.1120, test loss 0.1266\n",
      "Epoch 2029: train loss: 0.1120, test loss 0.1256\n",
      "Epoch 2030: train loss: 0.1120, test loss 0.1252\n",
      "Epoch 2031: train loss: 0.1119, test loss 0.1258\n",
      "Epoch 2032: train loss: 0.1119, test loss 0.1258\n",
      "Epoch 2033: train loss: 0.1119, test loss 0.1256\n",
      "Epoch 2034: train loss: 0.1119, test loss 0.1258\n",
      "Epoch 2035: train loss: 0.1119, test loss 0.1255\n",
      "Epoch 2036: train loss: 0.1119, test loss 0.1248\n",
      "Epoch 2037: train loss: 0.1119, test loss 0.1252\n",
      "Epoch 2038: train loss: 0.1119, test loss 0.1258\n",
      "Epoch 2039: train loss: 0.1119, test loss 0.1249\n",
      "Epoch 2040: train loss: 0.1119, test loss 0.1250\n",
      "Epoch 2041: train loss: 0.1119, test loss 0.1253\n",
      "Epoch 2042: train loss: 0.1118, test loss 0.1250\n",
      "Epoch 2043: train loss: 0.1118, test loss 0.1250\n",
      "Epoch 2044: train loss: 0.1118, test loss 0.1252\n",
      "Epoch 2045: train loss: 0.1118, test loss 0.1249\n",
      "Epoch 2046: train loss: 0.1118, test loss 0.1248\n",
      "Epoch 2047: train loss: 0.1118, test loss 0.1252\n",
      "Epoch 2048: train loss: 0.1118, test loss 0.1250\n",
      "Epoch 2049: train loss: 0.1118, test loss 0.1245\n",
      "Epoch 2050: train loss: 0.1118, test loss 0.1248\n",
      "Epoch 2051: train loss: 0.1118, test loss 0.1249\n",
      "Epoch 2052: train loss: 0.1118, test loss 0.1248\n",
      "Epoch 2053: train loss: 0.1118, test loss 0.1252\n",
      "Epoch 2054: train loss: 0.1117, test loss 0.1241\n",
      "Epoch 2055: train loss: 0.1117, test loss 0.1243\n",
      "Epoch 2056: train loss: 0.1117, test loss 0.1256\n",
      "Epoch 2057: train loss: 0.1117, test loss 0.1250\n",
      "Epoch 2058: train loss: 0.1117, test loss 0.1238\n",
      "Epoch 2059: train loss: 0.1117, test loss 0.1246\n",
      "Epoch 2060: train loss: 0.1117, test loss 0.1251\n",
      "Epoch 2061: train loss: 0.1117, test loss 0.1244\n",
      "Epoch 2062: train loss: 0.1117, test loss 0.1250\n",
      "Epoch 2063: train loss: 0.1117, test loss 0.1244\n",
      "Epoch 2064: train loss: 0.1117, test loss 0.1240\n",
      "Epoch 2065: train loss: 0.1117, test loss 0.1252\n",
      "Epoch 2066: train loss: 0.1116, test loss 0.1251\n",
      "Epoch 2067: train loss: 0.1116, test loss 0.1241\n",
      "Epoch 2068: train loss: 0.1116, test loss 0.1244\n",
      "Epoch 2069: train loss: 0.1116, test loss 0.1249\n",
      "Epoch 2070: train loss: 0.1116, test loss 0.1245\n",
      "Epoch 2071: train loss: 0.1116, test loss 0.1248\n",
      "Epoch 2072: train loss: 0.1116, test loss 0.1245\n",
      "Epoch 2073: train loss: 0.1116, test loss 0.1241\n",
      "Epoch 2074: train loss: 0.1116, test loss 0.1250\n",
      "Epoch 2075: train loss: 0.1116, test loss 0.1250\n",
      "Epoch 2076: train loss: 0.1116, test loss 0.1242\n",
      "Epoch 2077: train loss: 0.1116, test loss 0.1247\n",
      "Epoch 2078: train loss: 0.1116, test loss 0.1248\n",
      "Epoch 2079: train loss: 0.1115, test loss 0.1243\n",
      "Epoch 2080: train loss: 0.1115, test loss 0.1247\n",
      "Epoch 2081: train loss: 0.1115, test loss 0.1247\n",
      "Epoch 2082: train loss: 0.1115, test loss 0.1243\n",
      "Epoch 2083: train loss: 0.1115, test loss 0.1247\n",
      "Epoch 2084: train loss: 0.1115, test loss 0.1247\n",
      "Epoch 2085: train loss: 0.1115, test loss 0.1240\n",
      "Epoch 2086: train loss: 0.1115, test loss 0.1244\n",
      "Epoch 2087: train loss: 0.1115, test loss 0.1246\n",
      "Epoch 2088: train loss: 0.1115, test loss 0.1242\n",
      "Epoch 2089: train loss: 0.1115, test loss 0.1243\n",
      "Epoch 2090: train loss: 0.1115, test loss 0.1243\n",
      "Epoch 2091: train loss: 0.1114, test loss 0.1241\n",
      "Epoch 2092: train loss: 0.1114, test loss 0.1244\n",
      "Epoch 2093: train loss: 0.1114, test loss 0.1243\n",
      "Epoch 2094: train loss: 0.1114, test loss 0.1237\n",
      "Epoch 2095: train loss: 0.1114, test loss 0.1242\n",
      "Epoch 2096: train loss: 0.1114, test loss 0.1242\n",
      "Epoch 2097: train loss: 0.1114, test loss 0.1243\n",
      "Epoch 2098: train loss: 0.1114, test loss 0.1240\n",
      "Epoch 2099: train loss: 0.1114, test loss 0.1237\n",
      "Epoch 2100: train loss: 0.1114, test loss 0.1241\n",
      "Epoch 2101: train loss: 0.1114, test loss 0.1241\n",
      "Epoch 2102: train loss: 0.1114, test loss 0.1239\n",
      "Epoch 2103: train loss: 0.1114, test loss 0.1239\n",
      "Epoch 2104: train loss: 0.1113, test loss 0.1238\n",
      "Epoch 2105: train loss: 0.1113, test loss 0.1239\n",
      "Epoch 2106: train loss: 0.1113, test loss 0.1241\n",
      "Epoch 2107: train loss: 0.1113, test loss 0.1238\n",
      "Epoch 2108: train loss: 0.1113, test loss 0.1237\n",
      "Epoch 2109: train loss: 0.1113, test loss 0.1241\n",
      "Epoch 2110: train loss: 0.1113, test loss 0.1237\n",
      "Epoch 2111: train loss: 0.1113, test loss 0.1238\n",
      "Epoch 2112: train loss: 0.1113, test loss 0.1239\n",
      "Epoch 2113: train loss: 0.1113, test loss 0.1235\n",
      "Epoch 2114: train loss: 0.1113, test loss 0.1238\n",
      "Epoch 2115: train loss: 0.1113, test loss 0.1239\n",
      "Epoch 2116: train loss: 0.1113, test loss 0.1233\n",
      "Epoch 2117: train loss: 0.1112, test loss 0.1239\n",
      "Epoch 2118: train loss: 0.1112, test loss 0.1238\n",
      "Epoch 2119: train loss: 0.1112, test loss 0.1235\n",
      "Epoch 2120: train loss: 0.1112, test loss 0.1237\n",
      "Epoch 2121: train loss: 0.1112, test loss 0.1232\n",
      "Epoch 2122: train loss: 0.1112, test loss 0.1235\n",
      "Epoch 2123: train loss: 0.1112, test loss 0.1237\n",
      "Epoch 2124: train loss: 0.1112, test loss 0.1233\n",
      "Epoch 2125: train loss: 0.1112, test loss 0.1235\n",
      "Epoch 2126: train loss: 0.1112, test loss 0.1235\n",
      "Epoch 2127: train loss: 0.1112, test loss 0.1231\n",
      "Epoch 2128: train loss: 0.1112, test loss 0.1234\n",
      "Epoch 2129: train loss: 0.1112, test loss 0.1233\n",
      "Epoch 2130: train loss: 0.1111, test loss 0.1232\n",
      "Epoch 2131: train loss: 0.1111, test loss 0.1235\n",
      "Epoch 2132: train loss: 0.1111, test loss 0.1234\n",
      "Epoch 2133: train loss: 0.1111, test loss 0.1230\n",
      "Epoch 2134: train loss: 0.1111, test loss 0.1234\n",
      "Epoch 2135: train loss: 0.1111, test loss 0.1233\n",
      "Epoch 2136: train loss: 0.1111, test loss 0.1232\n",
      "Epoch 2137: train loss: 0.1111, test loss 0.1237\n",
      "Epoch 2138: train loss: 0.1111, test loss 0.1232\n",
      "Epoch 2139: train loss: 0.1111, test loss 0.1230\n",
      "Epoch 2140: train loss: 0.1111, test loss 0.1234\n",
      "Epoch 2141: train loss: 0.1111, test loss 0.1231\n",
      "Epoch 2142: train loss: 0.1110, test loss 0.1233\n",
      "Epoch 2143: train loss: 0.1110, test loss 0.1236\n",
      "Epoch 2144: train loss: 0.1110, test loss 0.1230\n",
      "Epoch 2145: train loss: 0.1110, test loss 0.1230\n",
      "Epoch 2146: train loss: 0.1110, test loss 0.1231\n",
      "Epoch 2147: train loss: 0.1110, test loss 0.1229\n",
      "Epoch 2148: train loss: 0.1110, test loss 0.1232\n",
      "Epoch 2149: train loss: 0.1110, test loss 0.1227\n",
      "Epoch 2150: train loss: 0.1110, test loss 0.1225\n",
      "Epoch 2151: train loss: 0.1110, test loss 0.1227\n",
      "Epoch 2152: train loss: 0.1110, test loss 0.1228\n",
      "Epoch 2153: train loss: 0.1109, test loss 0.1226\n",
      "Epoch 2154: train loss: 0.1109, test loss 0.1225\n",
      "Epoch 2155: train loss: 0.1109, test loss 0.1220\n",
      "Epoch 2156: train loss: 0.1109, test loss 0.1226\n",
      "Epoch 2157: train loss: 0.1109, test loss 0.1226\n",
      "Epoch 2158: train loss: 0.1109, test loss 0.1220\n",
      "Epoch 2159: train loss: 0.1109, test loss 0.1223\n",
      "Epoch 2160: train loss: 0.1109, test loss 0.1224\n",
      "Epoch 2161: train loss: 0.1109, test loss 0.1218\n",
      "Epoch 2162: train loss: 0.1109, test loss 0.1220\n",
      "Epoch 2163: train loss: 0.1109, test loss 0.1220\n",
      "Epoch 2164: train loss: 0.1108, test loss 0.1221\n",
      "Epoch 2165: train loss: 0.1108, test loss 0.1224\n",
      "Epoch 2166: train loss: 0.1108, test loss 0.1219\n",
      "Epoch 2167: train loss: 0.1108, test loss 0.1216\n",
      "Epoch 2168: train loss: 0.1108, test loss 0.1222\n",
      "Epoch 2169: train loss: 0.1108, test loss 0.1222\n",
      "Epoch 2170: train loss: 0.1108, test loss 0.1219\n",
      "Epoch 2171: train loss: 0.1108, test loss 0.1223\n",
      "Epoch 2172: train loss: 0.1108, test loss 0.1216\n",
      "Epoch 2173: train loss: 0.1108, test loss 0.1222\n",
      "Epoch 2174: train loss: 0.1108, test loss 0.1223\n",
      "Epoch 2175: train loss: 0.1108, test loss 0.1215\n",
      "Epoch 2176: train loss: 0.1107, test loss 0.1218\n",
      "Epoch 2177: train loss: 0.1107, test loss 0.1222\n",
      "Epoch 2178: train loss: 0.1107, test loss 0.1217\n",
      "Epoch 2179: train loss: 0.1107, test loss 0.1220\n",
      "Epoch 2180: train loss: 0.1107, test loss 0.1219\n",
      "Epoch 2181: train loss: 0.1107, test loss 0.1216\n",
      "Epoch 2182: train loss: 0.1107, test loss 0.1221\n",
      "Epoch 2183: train loss: 0.1107, test loss 0.1217\n",
      "Epoch 2184: train loss: 0.1107, test loss 0.1216\n",
      "Epoch 2185: train loss: 0.1107, test loss 0.1221\n",
      "Epoch 2186: train loss: 0.1106, test loss 0.1218\n",
      "Epoch 2187: train loss: 0.1106, test loss 0.1216\n",
      "Epoch 2188: train loss: 0.1106, test loss 0.1220\n",
      "Epoch 2189: train loss: 0.1106, test loss 0.1217\n",
      "Epoch 2190: train loss: 0.1106, test loss 0.1217\n",
      "Epoch 2191: train loss: 0.1106, test loss 0.1221\n",
      "Epoch 2192: train loss: 0.1106, test loss 0.1215\n",
      "Epoch 2193: train loss: 0.1106, test loss 0.1218\n",
      "Epoch 2194: train loss: 0.1106, test loss 0.1217\n",
      "Epoch 2195: train loss: 0.1106, test loss 0.1219\n",
      "Epoch 2196: train loss: 0.1106, test loss 0.1217\n",
      "Epoch 2197: train loss: 0.1105, test loss 0.1213\n",
      "Epoch 2198: train loss: 0.1105, test loss 0.1219\n",
      "Epoch 2199: train loss: 0.1105, test loss 0.1217\n",
      "Epoch 2200: train loss: 0.1105, test loss 0.1215\n",
      "Epoch 2201: train loss: 0.1105, test loss 0.1218\n",
      "Epoch 2202: train loss: 0.1105, test loss 0.1213\n",
      "Epoch 2203: train loss: 0.1105, test loss 0.1219\n",
      "Epoch 2204: train loss: 0.1105, test loss 0.1214\n",
      "Epoch 2205: train loss: 0.1105, test loss 0.1211\n",
      "Epoch 2206: train loss: 0.1105, test loss 0.1217\n",
      "Epoch 2207: train loss: 0.1104, test loss 0.1213\n",
      "Epoch 2208: train loss: 0.1104, test loss 0.1213\n",
      "Epoch 2209: train loss: 0.1104, test loss 0.1212\n",
      "Epoch 2210: train loss: 0.1104, test loss 0.1208\n",
      "Epoch 2211: train loss: 0.1104, test loss 0.1211\n",
      "Epoch 2212: train loss: 0.1104, test loss 0.1210\n",
      "Epoch 2213: train loss: 0.1104, test loss 0.1208\n",
      "Epoch 2214: train loss: 0.1104, test loss 0.1210\n",
      "Epoch 2215: train loss: 0.1104, test loss 0.1207\n",
      "Epoch 2216: train loss: 0.1104, test loss 0.1205\n",
      "Epoch 2217: train loss: 0.1104, test loss 0.1205\n",
      "Epoch 2218: train loss: 0.1104, test loss 0.1206\n",
      "Epoch 2219: train loss: 0.1103, test loss 0.1212\n",
      "Epoch 2220: train loss: 0.1103, test loss 0.1200\n",
      "Epoch 2221: train loss: 0.1103, test loss 0.1198\n",
      "Epoch 2222: train loss: 0.1103, test loss 0.1204\n",
      "Epoch 2223: train loss: 0.1103, test loss 0.1208\n",
      "Epoch 2224: train loss: 0.1103, test loss 0.1204\n",
      "Epoch 2225: train loss: 0.1103, test loss 0.1204\n",
      "Epoch 2226: train loss: 0.1103, test loss 0.1199\n",
      "Epoch 2227: train loss: 0.1103, test loss 0.1198\n",
      "Epoch 2228: train loss: 0.1103, test loss 0.1206\n",
      "Epoch 2229: train loss: 0.1102, test loss 0.1200\n",
      "Epoch 2230: train loss: 0.1102, test loss 0.1197\n",
      "Epoch 2231: train loss: 0.1102, test loss 0.1203\n",
      "Epoch 2232: train loss: 0.1102, test loss 0.1196\n",
      "Epoch 2233: train loss: 0.1102, test loss 0.1200\n",
      "Epoch 2234: train loss: 0.1102, test loss 0.1201\n",
      "Epoch 2235: train loss: 0.1102, test loss 0.1193\n",
      "Epoch 2236: train loss: 0.1102, test loss 0.1202\n",
      "Epoch 2237: train loss: 0.1102, test loss 0.1197\n",
      "Epoch 2238: train loss: 0.1102, test loss 0.1189\n",
      "Epoch 2239: train loss: 0.1102, test loss 0.1198\n",
      "Epoch 2240: train loss: 0.1101, test loss 0.1194\n",
      "Epoch 2241: train loss: 0.1101, test loss 0.1194\n",
      "Epoch 2242: train loss: 0.1101, test loss 0.1198\n",
      "Epoch 2243: train loss: 0.1101, test loss 0.1189\n",
      "Epoch 2244: train loss: 0.1101, test loss 0.1194\n",
      "Epoch 2245: train loss: 0.1101, test loss 0.1198\n",
      "Epoch 2246: train loss: 0.1101, test loss 0.1188\n",
      "Epoch 2247: train loss: 0.1101, test loss 0.1194\n",
      "Epoch 2248: train loss: 0.1101, test loss 0.1193\n",
      "Epoch 2249: train loss: 0.1101, test loss 0.1189\n",
      "Epoch 2250: train loss: 0.1101, test loss 0.1195\n",
      "Epoch 2251: train loss: 0.1101, test loss 0.1189\n",
      "Epoch 2252: train loss: 0.1100, test loss 0.1190\n",
      "Epoch 2253: train loss: 0.1100, test loss 0.1196\n",
      "Epoch 2254: train loss: 0.1100, test loss 0.1190\n",
      "Epoch 2255: train loss: 0.1100, test loss 0.1192\n",
      "Epoch 2256: train loss: 0.1100, test loss 0.1192\n",
      "Epoch 2257: train loss: 0.1100, test loss 0.1189\n",
      "Epoch 2258: train loss: 0.1100, test loss 0.1198\n",
      "Epoch 2259: train loss: 0.1100, test loss 0.1190\n",
      "Epoch 2260: train loss: 0.1100, test loss 0.1195\n",
      "Epoch 2261: train loss: 0.1100, test loss 0.1195\n",
      "Epoch 2262: train loss: 0.1100, test loss 0.1190\n",
      "Epoch 2263: train loss: 0.1100, test loss 0.1199\n",
      "Epoch 2264: train loss: 0.1099, test loss 0.1194\n",
      "Epoch 2265: train loss: 0.1099, test loss 0.1191\n",
      "Epoch 2266: train loss: 0.1099, test loss 0.1199\n",
      "Epoch 2267: train loss: 0.1099, test loss 0.1191\n",
      "Epoch 2268: train loss: 0.1099, test loss 0.1200\n",
      "Epoch 2269: train loss: 0.1099, test loss 0.1189\n",
      "Epoch 2270: train loss: 0.1099, test loss 0.1196\n",
      "Epoch 2271: train loss: 0.1099, test loss 0.1201\n",
      "Epoch 2272: train loss: 0.1099, test loss 0.1188\n",
      "Epoch 2273: train loss: 0.1099, test loss 0.1202\n",
      "Epoch 2274: train loss: 0.1099, test loss 0.1187\n",
      "Epoch 2275: train loss: 0.1099, test loss 0.1201\n",
      "Epoch 2276: train loss: 0.1098, test loss 0.1191\n",
      "Epoch 2277: train loss: 0.1098, test loss 0.1194\n",
      "Epoch 2278: train loss: 0.1098, test loss 0.1202\n",
      "Epoch 2279: train loss: 0.1098, test loss 0.1186\n",
      "Epoch 2280: train loss: 0.1098, test loss 0.1199\n",
      "Epoch 2281: train loss: 0.1098, test loss 0.1195\n",
      "Epoch 2282: train loss: 0.1098, test loss 0.1194\n",
      "Epoch 2283: train loss: 0.1098, test loss 0.1201\n",
      "Epoch 2284: train loss: 0.1098, test loss 0.1192\n",
      "Epoch 2285: train loss: 0.1098, test loss 0.1201\n",
      "Epoch 2286: train loss: 0.1098, test loss 0.1199\n",
      "Epoch 2287: train loss: 0.1098, test loss 0.1196\n",
      "Epoch 2288: train loss: 0.1098, test loss 0.1204\n",
      "Epoch 2289: train loss: 0.1097, test loss 0.1195\n",
      "Epoch 2290: train loss: 0.1097, test loss 0.1203\n",
      "Epoch 2291: train loss: 0.1097, test loss 0.1199\n",
      "Epoch 2292: train loss: 0.1097, test loss 0.1200\n",
      "Epoch 2293: train loss: 0.1097, test loss 0.1204\n",
      "Epoch 2294: train loss: 0.1097, test loss 0.1199\n",
      "Epoch 2295: train loss: 0.1097, test loss 0.1204\n",
      "Epoch 2296: train loss: 0.1097, test loss 0.1204\n",
      "Epoch 2297: train loss: 0.1097, test loss 0.1202\n",
      "Epoch 2298: train loss: 0.1097, test loss 0.1206\n",
      "Epoch 2299: train loss: 0.1097, test loss 0.1203\n",
      "Epoch 2300: train loss: 0.1096, test loss 0.1208\n",
      "Epoch 2301: train loss: 0.1096, test loss 0.1208\n",
      "Epoch 2302: train loss: 0.1096, test loss 0.1211\n",
      "Epoch 2303: train loss: 0.1096, test loss 0.1210\n",
      "Epoch 2304: train loss: 0.1096, test loss 0.1208\n",
      "Epoch 2305: train loss: 0.1096, test loss 0.1211\n",
      "Epoch 2306: train loss: 0.1096, test loss 0.1210\n",
      "Epoch 2307: train loss: 0.1096, test loss 0.1214\n",
      "Epoch 2308: train loss: 0.1096, test loss 0.1209\n",
      "Epoch 2309: train loss: 0.1096, test loss 0.1214\n",
      "Epoch 2310: train loss: 0.1096, test loss 0.1212\n",
      "Epoch 2311: train loss: 0.1096, test loss 0.1214\n",
      "Epoch 2312: train loss: 0.1096, test loss 0.1214\n",
      "Epoch 2313: train loss: 0.1096, test loss 0.1210\n",
      "Epoch 2314: train loss: 0.1095, test loss 0.1219\n",
      "Epoch 2315: train loss: 0.1095, test loss 0.1213\n",
      "Epoch 2316: train loss: 0.1095, test loss 0.1216\n",
      "Epoch 2317: train loss: 0.1095, test loss 0.1216\n",
      "Epoch 2318: train loss: 0.1095, test loss 0.1217\n",
      "Epoch 2319: train loss: 0.1095, test loss 0.1220\n",
      "Epoch 2320: train loss: 0.1095, test loss 0.1212\n",
      "Epoch 2321: train loss: 0.1095, test loss 0.1223\n",
      "Epoch 2322: train loss: 0.1095, test loss 0.1214\n",
      "Epoch 2323: train loss: 0.1095, test loss 0.1217\n",
      "Epoch 2324: train loss: 0.1095, test loss 0.1217\n",
      "Epoch 2325: train loss: 0.1095, test loss 0.1221\n",
      "Epoch 2326: train loss: 0.1095, test loss 0.1223\n",
      "Epoch 2327: train loss: 0.1094, test loss 0.1219\n",
      "Epoch 2328: train loss: 0.1094, test loss 0.1220\n",
      "Epoch 2329: train loss: 0.1094, test loss 0.1223\n",
      "Epoch 2330: train loss: 0.1094, test loss 0.1226\n",
      "Epoch 2331: train loss: 0.1094, test loss 0.1219\n",
      "Epoch 2332: train loss: 0.1094, test loss 0.1226\n",
      "Epoch 2333: train loss: 0.1094, test loss 0.1222\n",
      "Epoch 2334: train loss: 0.1094, test loss 0.1227\n",
      "Epoch 2335: train loss: 0.1094, test loss 0.1224\n",
      "Epoch 2336: train loss: 0.1094, test loss 0.1227\n",
      "Epoch 2337: train loss: 0.1094, test loss 0.1230\n",
      "Epoch 2338: train loss: 0.1094, test loss 0.1225\n",
      "Epoch 2339: train loss: 0.1094, test loss 0.1229\n",
      "Epoch 2340: train loss: 0.1094, test loss 0.1224\n",
      "Epoch 2341: train loss: 0.1094, test loss 0.1234\n",
      "Epoch 2342: train loss: 0.1093, test loss 0.1228\n",
      "Epoch 2343: train loss: 0.1093, test loss 0.1232\n",
      "Epoch 2344: train loss: 0.1093, test loss 0.1229\n",
      "Epoch 2345: train loss: 0.1093, test loss 0.1231\n",
      "Epoch 2346: train loss: 0.1093, test loss 0.1231\n",
      "Epoch 2347: train loss: 0.1093, test loss 0.1233\n",
      "Epoch 2348: train loss: 0.1093, test loss 0.1231\n",
      "Epoch 2349: train loss: 0.1094, test loss 0.1234\n",
      "Epoch 2350: train loss: 0.1094, test loss 0.1209\n",
      "Epoch 2351: train loss: 0.1095, test loss 0.1246\n",
      "Epoch 2352: train loss: 0.1094, test loss 0.1214\n",
      "Epoch 2353: train loss: 0.1094, test loss 0.1232\n",
      "Epoch 2354: train loss: 0.1093, test loss 0.1209\n",
      "Epoch 2355: train loss: 0.1093, test loss 0.1226\n",
      "Epoch 2356: train loss: 0.1093, test loss 0.1243\n",
      "Epoch 2357: train loss: 0.1093, test loss 0.1215\n",
      "Epoch 2358: train loss: 0.1093, test loss 0.1229\n",
      "Epoch 2359: train loss: 0.1092, test loss 0.1217\n",
      "Epoch 2360: train loss: 0.1092, test loss 0.1231\n",
      "Epoch 2361: train loss: 0.1093, test loss 0.1237\n",
      "Epoch 2362: train loss: 0.1093, test loss 0.1209\n",
      "Epoch 2363: train loss: 0.1093, test loss 0.1227\n",
      "Epoch 2364: train loss: 0.1092, test loss 0.1224\n",
      "Epoch 2365: train loss: 0.1092, test loss 0.1231\n",
      "Epoch 2366: train loss: 0.1093, test loss 0.1229\n",
      "Epoch 2367: train loss: 0.1093, test loss 0.1200\n",
      "Epoch 2368: train loss: 0.1094, test loss 0.1242\n",
      "Epoch 2369: train loss: 0.1094, test loss 0.1206\n",
      "Epoch 2370: train loss: 0.1093, test loss 0.1231\n",
      "Epoch 2371: train loss: 0.1092, test loss 0.1201\n",
      "Epoch 2372: train loss: 0.1091, test loss 0.1213\n",
      "Epoch 2373: train loss: 0.1092, test loss 0.1235\n",
      "Epoch 2374: train loss: 0.1093, test loss 0.1204\n",
      "Epoch 2375: train loss: 0.1093, test loss 0.1231\n",
      "Epoch 2376: train loss: 0.1092, test loss 0.1197\n",
      "Epoch 2377: train loss: 0.1091, test loss 0.1228\n",
      "Epoch 2378: train loss: 0.1091, test loss 0.1238\n",
      "Epoch 2379: train loss: 0.1092, test loss 0.1205\n",
      "Epoch 2380: train loss: 0.1093, test loss 0.1229\n",
      "Epoch 2381: train loss: 0.1092, test loss 0.1197\n",
      "Epoch 2382: train loss: 0.1091, test loss 0.1237\n",
      "Epoch 2383: train loss: 0.1091, test loss 0.1220\n",
      "Epoch 2384: train loss: 0.1090, test loss 0.1206\n",
      "Epoch 2385: train loss: 0.1090, test loss 0.1206\n",
      "Epoch 2386: train loss: 0.1090, test loss 0.1207\n",
      "Epoch 2387: train loss: 0.1090, test loss 0.1223\n",
      "Epoch 2388: train loss: 0.1090, test loss 0.1201\n",
      "Epoch 2389: train loss: 0.1090, test loss 0.1201\n",
      "Epoch 2390: train loss: 0.1090, test loss 0.1198\n",
      "Epoch 2391: train loss: 0.1090, test loss 0.1213\n",
      "Epoch 2392: train loss: 0.1089, test loss 0.1211\n",
      "Epoch 2393: train loss: 0.1089, test loss 0.1194\n",
      "Epoch 2394: train loss: 0.1089, test loss 0.1200\n",
      "Epoch 2395: train loss: 0.1089, test loss 0.1202\n",
      "Epoch 2396: train loss: 0.1090, test loss 0.1210\n",
      "Epoch 2397: train loss: 0.1091, test loss 0.1177\n",
      "Epoch 2398: train loss: 0.1093, test loss 0.1221\n",
      "Epoch 2399: train loss: 0.1094, test loss 0.1165\n",
      "Epoch 2400: train loss: 0.1094, test loss 0.1224\n",
      "Epoch 2401: train loss: 0.1091, test loss 0.1165\n",
      "Epoch 2402: train loss: 0.1089, test loss 0.1197\n",
      "Epoch 2403: train loss: 0.1089, test loss 0.1200\n",
      "Epoch 2404: train loss: 0.1091, test loss 0.1172\n",
      "Epoch 2405: train loss: 0.1094, test loss 0.1222\n",
      "Epoch 2406: train loss: 0.1096, test loss 0.1147\n",
      "Epoch 2407: train loss: 0.1097, test loss 0.1230\n",
      "Epoch 2408: train loss: 0.1093, test loss 0.1151\n",
      "Epoch 2409: train loss: 0.1091, test loss 0.1196\n",
      "Epoch 2410: train loss: 0.1088, test loss 0.1163\n",
      "Epoch 2411: train loss: 0.1089, test loss 0.1163\n",
      "Epoch 2412: train loss: 0.1090, test loss 0.1203\n",
      "Epoch 2413: train loss: 0.1090, test loss 0.1147\n",
      "Epoch 2414: train loss: 0.1089, test loss 0.1190\n",
      "Epoch 2415: train loss: 0.1088, test loss 0.1166\n",
      "Epoch 2416: train loss: 0.1087, test loss 0.1179\n",
      "Epoch 2417: train loss: 0.1088, test loss 0.1190\n",
      "Epoch 2418: train loss: 0.1089, test loss 0.1158\n",
      "Epoch 2419: train loss: 0.1091, test loss 0.1195\n",
      "Epoch 2420: train loss: 0.1091, test loss 0.1135\n",
      "Epoch 2421: train loss: 0.1091, test loss 0.1200\n",
      "Epoch 2422: train loss: 0.1090, test loss 0.1138\n",
      "Epoch 2423: train loss: 0.1087, test loss 0.1173\n",
      "Epoch 2424: train loss: 0.1087, test loss 0.1171\n",
      "Epoch 2425: train loss: 0.1089, test loss 0.1139\n",
      "Epoch 2426: train loss: 0.1089, test loss 0.1198\n",
      "Epoch 2427: train loss: 0.1089, test loss 0.1149\n",
      "Epoch 2428: train loss: 0.1090, test loss 0.1193\n",
      "Epoch 2429: train loss: 0.1089, test loss 0.1138\n",
      "Epoch 2430: train loss: 0.1087, test loss 0.1187\n",
      "Epoch 2431: train loss: 0.1086, test loss 0.1167\n",
      "Epoch 2432: train loss: 0.1086, test loss 0.1160\n",
      "Epoch 2433: train loss: 0.1087, test loss 0.1179\n",
      "Epoch 2434: train loss: 0.1088, test loss 0.1145\n",
      "Epoch 2435: train loss: 0.1088, test loss 0.1197\n",
      "Epoch 2436: train loss: 0.1087, test loss 0.1160\n",
      "Epoch 2437: train loss: 0.1087, test loss 0.1183\n",
      "Epoch 2438: train loss: 0.1087, test loss 0.1150\n",
      "Epoch 2439: train loss: 0.1086, test loss 0.1184\n",
      "Epoch 2440: train loss: 0.1086, test loss 0.1183\n",
      "Epoch 2441: train loss: 0.1086, test loss 0.1166\n",
      "Epoch 2442: train loss: 0.1086, test loss 0.1180\n",
      "Epoch 2443: train loss: 0.1086, test loss 0.1161\n",
      "Epoch 2444: train loss: 0.1086, test loss 0.1198\n",
      "Epoch 2445: train loss: 0.1086, test loss 0.1174\n",
      "Epoch 2446: train loss: 0.1086, test loss 0.1184\n",
      "Epoch 2447: train loss: 0.1086, test loss 0.1159\n",
      "Epoch 2448: train loss: 0.1085, test loss 0.1193\n",
      "Epoch 2449: train loss: 0.1085, test loss 0.1180\n",
      "Epoch 2450: train loss: 0.1085, test loss 0.1184\n",
      "Epoch 2451: train loss: 0.1085, test loss 0.1170\n",
      "Epoch 2452: train loss: 0.1085, test loss 0.1178\n",
      "Epoch 2453: train loss: 0.1085, test loss 0.1190\n",
      "Epoch 2454: train loss: 0.1084, test loss 0.1184\n",
      "Epoch 2455: train loss: 0.1084, test loss 0.1181\n",
      "Epoch 2456: train loss: 0.1084, test loss 0.1176\n",
      "Epoch 2457: train loss: 0.1084, test loss 0.1190\n",
      "Epoch 2458: train loss: 0.1084, test loss 0.1188\n",
      "Epoch 2459: train loss: 0.1084, test loss 0.1186\n",
      "Epoch 2460: train loss: 0.1084, test loss 0.1176\n",
      "Epoch 2461: train loss: 0.1084, test loss 0.1189\n",
      "Epoch 2462: train loss: 0.1084, test loss 0.1191\n",
      "Epoch 2463: train loss: 0.1084, test loss 0.1195\n",
      "Epoch 2464: train loss: 0.1084, test loss 0.1179\n",
      "Epoch 2465: train loss: 0.1084, test loss 0.1193\n",
      "Epoch 2466: train loss: 0.1084, test loss 0.1185\n",
      "Epoch 2467: train loss: 0.1084, test loss 0.1201\n",
      "Epoch 2468: train loss: 0.1084, test loss 0.1179\n",
      "Epoch 2469: train loss: 0.1084, test loss 0.1197\n",
      "Epoch 2470: train loss: 0.1084, test loss 0.1180\n",
      "Epoch 2471: train loss: 0.1084, test loss 0.1205\n",
      "Epoch 2472: train loss: 0.1083, test loss 0.1182\n",
      "Epoch 2473: train loss: 0.1083, test loss 0.1201\n",
      "Epoch 2474: train loss: 0.1083, test loss 0.1182\n",
      "Epoch 2475: train loss: 0.1083, test loss 0.1206\n",
      "Epoch 2476: train loss: 0.1083, test loss 0.1185\n",
      "Epoch 2477: train loss: 0.1083, test loss 0.1202\n",
      "Epoch 2478: train loss: 0.1083, test loss 0.1177\n",
      "Epoch 2479: train loss: 0.1083, test loss 0.1208\n",
      "Epoch 2480: train loss: 0.1083, test loss 0.1181\n",
      "Epoch 2481: train loss: 0.1084, test loss 0.1207\n",
      "Epoch 2482: train loss: 0.1085, test loss 0.1163\n",
      "Epoch 2483: train loss: 0.1085, test loss 0.1224\n",
      "Epoch 2484: train loss: 0.1086, test loss 0.1167\n",
      "Epoch 2485: train loss: 0.1089, test loss 0.1219\n",
      "Epoch 2486: train loss: 0.1091, test loss 0.1134\n",
      "Epoch 2487: train loss: 0.1092, test loss 0.1248\n",
      "Epoch 2488: train loss: 0.1092, test loss 0.1151\n",
      "Epoch 2489: train loss: 0.1092, test loss 0.1229\n",
      "Epoch 2490: train loss: 0.1091, test loss 0.1125\n",
      "Epoch 2491: train loss: 0.1088, test loss 0.1229\n",
      "Epoch 2492: train loss: 0.1084, test loss 0.1167\n",
      "Epoch 2493: train loss: 0.1083, test loss 0.1186\n",
      "Epoch 2494: train loss: 0.1083, test loss 0.1146\n",
      "Epoch 2495: train loss: 0.1082, test loss 0.1176\n",
      "Epoch 2496: train loss: 0.1082, test loss 0.1197\n",
      "Epoch 2497: train loss: 0.1082, test loss 0.1167\n",
      "Epoch 2498: train loss: 0.1083, test loss 0.1186\n",
      "Epoch 2499: train loss: 0.1083, test loss 0.1150\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "loss_train_array = []\n",
    "loss_test_array = []\n",
    "epoch = 2500\n",
    "for epoch in range(epoch):\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass\n",
    "    loss_train = loss_fn(model(X_train), Y_train)\n",
    "    loss_train_array.append(loss_train)\n",
    "    loss_test = loss_fn(model(X_test), Y_test)\n",
    "    loss_test_array.append(loss_test)\n",
    "\n",
    "   \n",
    "    print('Epoch %s: train loss: %6.4f, test loss %6.4f'%(epoch, loss_train.item(), loss_test.item()))\n",
    "    # Backward pass\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 960x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,3), dpi=120)\n",
    "plt.plot(loss_train_array)\n",
    "plt.plot(loss_test_array)\n",
    "plt.legend(['train loss', 'test loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('mse loss')\n",
    "plt.ylim([0,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and testing for each cordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "X_pred = model(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Pred'] = X_pred.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_co_ord = OrderedDict()\n",
    "for co_ord, df_c in df_test.groupby(['lat','lon']):\n",
    "    loss = (df_c['Pred'] - df_c['lambda'])**2\n",
    "    loss_co_ord[str(co_ord)] = loss\n",
    "    # loss_co_ord.append(loss.detach().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,3), dpi=120)\n",
    "plt.bar(loss_co_ord.keys(), [x.mean() for x in loss_co_ord.values()])\n",
    "# notch shape box plot\n",
    "# plt.boxplot(loss_co_ord.values(),\n",
    "#                      notch=True,  # notch shape\n",
    "#                      vert=True,  # vertical box alignment\n",
    "#                      patch_artist=True,  # fill with color\n",
    "#                      labels=loss_co_ord.keys())  # will be used to label x-ticks\n",
    "plt.ylim([0,1])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Model loss per co-ordinate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0aed7f3f2602e9ffc7bcdb3e0077e6e7eb290cd9bde9bdf0f85d0264c7b32cc9"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
